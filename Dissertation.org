#+TITLE: 
#+AUTHOR: Tais Bellini

#+STARTUP: overview indent
#+LANGUAGE: en
#+OPTIONS: H:3 creator:nil timestamp:nil skip:nil toc:nil num:t ^:nil ~:~
#+OPTIONS: author:nil title:nil date:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_CLASS: iiufrgs
#+LATEX_CLASS_OPTIONS: [times,cic,tc,english]
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage{tabulary}
#+LATEX_HEADER: \usepackage{tabularx}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{algorithmic}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \newcommand{\prettysmall}{\fontsize{6.5}{6.5}\selectfont}
#+LATEX_HEADER: \newcommand{\prettysmallbis}{\fontsize{7}{7}\selectfont}
#+LATEX_HEADER: \newcommand{\mtilde}{~}

#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{palatino}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{cleveref}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \graphicspath{{img/}{img/final/}}
#+LATEX_HEADER: \hypersetup{hidelinks = true}

#+LATEX_HEADER: \newcommand{\review}[1]{\textcolor[rgb]{1,0,0}{[Lucas: #1]}}
#+LATEX_HEADER: \newcommand{\lucas}[1]{\textcolor[rgb]{0.2,0.2,0.7}{[Lucas: #1]}}
#+LATEX_HEADER: \input{configuration.tex}

* Front page preparation                                           :noexport:

#+BEGIN_LaTeX
\title{Extensible Simulator for Replay of Trace Files in the Pajé format}
\author{Loureiro Bellini}{Tais}
\advisor[Prof.~Dr.]{Mello Schnorr}{Lucas}

\date{Maio}{2016}
\location{Porto Alegre}{RS}

% \renewcommand{\nominataReit}{Prof\textsuperscript{a}.~Wrana Maria Panizzi}
% \renewcommand{\nominataReitname}{Reitora}
% \renewcommand{\nominataPRE}{Prof.~Jos{\'e} Carlos Ferraz Hennemann}
% \renewcommand{\nominataPREname}{Pr{\'o}-Reitor de Ensino}
% \renewcommand{\nominataPRAPG}{Prof\textsuperscript{a}.~Joc{\'e}lia Grazia}
% \renewcommand{\nominataPRAPGname}{Pr{\'o}-Reitora Adjunta de P{\'o}s-Gradua{\c{c}}{\~a}o}
% \renewcommand{\nominataDir}{Prof.~Philippe Olivier Alexandre Navaux}
% \renewcommand{\nominataDirname}{Diretor do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataCoord}{Prof.~Carlos Alberto Heuser}
% \renewcommand{\nominataCoordname}{Coordenador do PPGC}
% \renewcommand{\nominataBibchefe}{Beatriz Regina Bastos Haro}
% \renewcommand{\nominataBibchefename}{Bibliotec{\'a}ria-chefe do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataChefeINA}{Prof.~Jos{\'e} Valdeni de Lima}
% \renewcommand{\nominataChefeINAname}{Chefe do \deptINA}
% \renewcommand{\nominataChefeINT}{Prof.~Leila Ribeiro}
% \renewcommand{\nominataChefeINTname}{Chefe do \deptINT}

%
% TODO: provide these keywords
%
% \keyword{formatação eletrônica de documentos}
% \keyword{\LaTeX}
% \keyword{ABNT}
% \keyword{UFRGS}
#+END_LaTeX

* Front page                                                       :noexport:
#+BEGIN_LaTeX
\maketitle
#+END_LaTeX
* Dedicatory                                                       :noexport:

#+BEGIN_LaTeX
% \clearpage
% \begin{flushright}
%     \mbox{}\vfill
%     {\sffamily\itshape
%       ``If I have seen farther than others,\\
%       it is because I stood on the shoulders of giants.''\\}
%     --- \textsc{Sir~Isaac Newton}
% \end{flushright}
#+END_LaTeX

* Acknowledgements                                                 :noexport:

#+BEGIN_LaTeX
% agradecimentos
%\chapter*{Agradecimentos}
%Agradeço ao \LaTeX\ por não ter vírus de macro\ldots
#+END_LaTeX

* Abstract                                                         :noexport:
                                                      
#+BEGIN_LaTeX
\begin{abstract}
#+END_LaTeX

Tracing is a very common method to observe program behavior, where
interesting program events are registered in trace files. Replaying
these trace files through simulation is used to analyze the data. The
simulation combines information that is spread in multiple events
deriving new and richer entities. Usually, this event processing is
done once and discarded, an approach adopted, for instance, by the
Pajé trace simulator. The objective of this proposal is to allow the
performance analyst to change the simulator behavior when entities are
detected according to his needs. This extensibility is implemented
through plugins, that could be developed by any programmer, where
every entity created is forwaded to it. It is the plugin's
responsibility to handle the entity. As a proof of concept, this work
presents the implementation of two plugins: a textual output similar
to an existing one in the Pajé tool; and a database insertion in a
pre-defined relational schema.  A performance analysis was developed
to compare Aiyra against the Pajé trace simulator. It is worth
highlighting that the new simulator had better performance results
with bigger files (over 120 Megabytes), that being possibly attributed
to the fact that it discards from memory entities that will no longer
be used. Additionally, the Pajé Insert Database plugin was evaluated
comparing its different possibilities of usage. In this investigation,
we varied the frequency of the insertions in the database by grouping
queries in memory. The aim of this test was to understand the impact
of the access to a database in the performance versus the memory
usage. The memory usage had more impact in the performance than the
accesses to the database themselves, probably due to the Garbage
Collector mechanism used by Java, the language used for the
implementation.

#+BEGIN_LaTeX
\end{abstract}
#+END_LaTeX

#+BEGIN_LaTeX
% resumo na outra língua
% como parametros devem ser passados o titulo e as palavras-chave
% na outra língua, separadas por vírgulas
\begin{englishabstract}{Titulo em pt-br.}{Palavra-chave 1. Palavra-chave 2.}
#+END_LaTeX

Put your Portuguese abstract here.

#+BEGIN_LaTeX
\end{englishabstract}
#+END_LaTeX
* Lists                                                            :noexport:

#+BEGIN_LaTeX
\listoffigures
\listoftables

% lista de abreviaturas e siglas
% o parametro deve ser a abreviatura mais longa
\begin{listofabbrv}{SPMD}
    \item[SMP] Symmetric Multi-Processor
    \item[NUMA] Non-Uniform Memory Access
    \item[SIMD] Single Instruction Multiple Data
    \item[SPMD] Single Program Multiple Data
    \item[ABNT] Associação Brasileira de Normas Técnicas
\end{listofabbrv}


% idem para a lista de símbolos
% \begin{listofsymbols}{$\alpha\beta\pi\omega$}
%     \item[$\sum{\frac{a}{b}}$] Somatório do produtório
%     \item[$\alpha\beta\pi\omega$] Fator de inconstância do resultado
% \end{listofsymbols}
#+END_LaTeX

* Sumário                                                          :noexport:

#+BEGIN_LaTeX
\tableofcontents
#+END_LaTeX

* Configuring Emacs to correctly export to PDF                     :noexport:

Org mode is configured by default to export only the base classes.

See for details:
+ http://orgmode.org/worg/org-tutorials/org-latex-export.html

Execute the following code (with C-c C-c) prior to export this file to PDF.

#+BEGIN_SRC emacs-lisp :results silent :exports none
(add-to-list 'load-path ".")
(require 'ox-extra)
(ox-extras-activate '(ignore-headlines))
(add-to-list 'org-latex-classes
             '("iiufrgs"
               "\\documentclass{iiufrgs}"
               ("\\chapter{%s}" . "\\chapter*{%s}")
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+END_SRC
* 2016-03-18 First entry (proper emacs configuration file)   :noexport:Lucas:

I recommend you use Arnaud's emacs configuration file, available here:
+ http://mescal.imag.fr/membres/arnaud.legrand/misc/init.php

Download the file =init.org=:

#+begin_src sh :results output :session :exports both
wget http://mescal.imag.fr/membres/arnaud.legrand/misc/init.org
#+end_src

#+RESULTS:

* 2016-04-29 How to compile with _bibtex_ entries              :Lucas:noexport:

Do as follows:

1. Export as usual to latex
2. Then, type in the terminal
   #+begin_src sh :results output :session :exports both
   pdflatex Dissertation.tex
   bibtex Dissertation
   pdflatex Dissertation.tex
   pdflatex Dissertation.tex
   #+end_src

* Introduction

_Global Comment_
- Check the PDF to respect all margins
- Compile latex manually with =pdflatex= after export to latex
  - Pay attention to these warnings: they are in fact errors
    - LaTeX Warning: There were undefined references.
    - LaTeX Warning: There were multiply-defined labels.
- All figures should be included as PDF (export to PDF with your
  figure editing tool), then include them here as PDF. That way, your
  figures will probably be vectorial, smaller and render much nicely
  in the final PDF.

Observation of program behavior is particularly important in High
Performance Computing since it enables an accurate performance
analysis. A very common method of evaluation is registering program
events in trace files that work as a log, so, whenever a relevant
event happens, it will be logged in the trace file with the proper
information. Then, these traces are replayed in simulation combining
information that is spread across multiple events deriving new and
richer entities. This event processing is usually done once and
discarded, which can be very inconvenient considering that some trace
files are very large. Therefore, it would be interesting to save these
entities for further analysis.

In this context of performance analysis, a common tool used is the
Pajé Trace Simulator \cite{kergommeaux2000paje}, an open source
project that reads trace files in a specific format, the Pajé Trace
File Format \cite{pajetracefile}, and processes five types of
entities: Containers, States, Events, Variables and Links. These
concepts represent basic structures of computer programs executed in
parallel or distributed systems, such as processes, threads, network
links, hardware counters and so on. As a base for the implementation
of this proposal, the new generation of Pajé, PajeNG \cite{pajeng},
was used. Details of PajeNG, the types of entities and the Pajé File
Format will be presented in Chapter \ref{chapter.paje}. Although it
has a visualization functionality, we will focus on the simulation
part of the Pajé implementation in this project. The most commonly
used tool of PajeNG is the Pajé
Dump\footnote{http://github.com/schnorr/pajeng/} (=pj_dump=), that
dumps to the standard output all information regarding entities
created throughout the simulation.

There are at least three problems with the current implementation of
Pajé: little extensibility, lack of partial outcomes and impermanent
results. The original Pajé and, consequently, its next generation were
idealized and built in an extensible way, that could be easily
expanded based on the user's needs. Although the implementation is
very modular, it is necessary to write a full component for Pajé,
which is a complex thing because it implies in understanding the
internal objects, class hierarchy, protocol, and so on. Until now,
very few people have actually extended this tool. Throughout the
simulation, the Pajé tool creates entities according to the events
listed in the trace file, saving each one of them in memory to dump
everything at once in the end. Since some trace files can be very
large (over 1 Gigabyte), it may take a while for the results to be
printed out. Besides not being able to have a partial view of already
simulated entities, the user won't have records of the results between
executions for different files unless he specifies a destination for
it himself. To address these issues, an extensible trace files
simulator, Aiyra, was developed in Java.

The objective of this proposal is to allow the performance analyst to
change the simulator behavior when a new entity is detected. Thus, the
partial results can be immediately presented to the user, or saved in
a database, or even discarded if not relevant. This extensibility is
implemented through the concept of plugins that are attached to the
simulator in specific and important points where the trace events are
combined. This main objective solves the lack of extensibility
problem. Once the simulator allows the immediate manipulation of the 
entities, the other two issues can be easily addressed with
extensions. Hence, the secondary objectives of the project are the 
creation of plugins to dump partial data that has just been simulated 
and to make the results permanent.

For the validation of the extensible trace files simulator, two
plugins were implemented: Paje Dump Plugin and Paje Insert Database
Plugin. The first one plays the same roll as the original Paje Dump
tool in the Paje new generation, with the difference that the entities
are dumped at the moment they are completed. The second one inserts
all the data in a relational database. A specific schema for the Pajé
Format was designed and will be presented in Chapter
\ref{chapter.plugins}.  A performance analysis was developed to
compare Aiyra against the previous one. It is worth highlighting that
the new simulator had better performance results with bigger files
(over 120 Megabytes), that being possibly attributed to the fact that
it discards from memory entities that will no longer be
used. Additionally, the Pajé Insert Database plugin was evaluated
comparing its different possibilities of usage. In this investigation,
we varied the frequency of the insertions in the database by grouping
queries in memory until it had a specific size to insert. The
objective of this test was to understand the impact of an access to a
database in the performance of the program. Likewise, the usage of the
memory was also examined to determine the best balance between
execution time and memory management. As we will see in Chapter 6, the
memory usage had more impact in the performance than the accesses to
the database themselves, probably due to the Garbage Collector
mechanism used by Java.

This document is organized as follows. Chapter
\ref{chapter.basic_concepts} provides the basic concepts of the
technologies used throughout the project.  Chapter \ref{chapter.paje}
gives an overview of the existing simulator for the Pajé format and
the problems with this current implementation. Chapter
\ref{chapter.aiyra} describes the details of the extensible simulator
developed in Java and Chapter \ref{chapter.plugins} characterize the
plugins developed. Chapter \ref{chapter.performance} presents a
performance analysis of the Pajé Insert Database Plugin and a
comparison between Aiyra and PajeNG.  The conclusion and final
considerations are expressed in Chapter \ref{chapter.conclusion}.

* Basic Concepts
\label{chapter.basic_concepts}

This chapter describes the basic notions of the concepts and
technologies used to develop this project. They contribute to the
understanding of our work. It is structured in five topics: the Java
Compiler Compiler (JavaCC), the Java Database Connectivity (JDBC) API
in the MySQL context, a brief description about the construction of
conceptual and logical database schemas, an overview about
experimental design, and the R language in the experimental design
context.

** The Java Compiler Compiler (JavaCC) tool
\label{section.javacc}

The Java Compiler Compiler (JavaCC) is a scanner and parser generator
configured with a set of regular expressions describing the tokens of
a language and a grammar using these tokens. As output, it generates a
lexical and syntax parser in the Java language. The lexical code
separates the input file into tokens; the parser code is responsible
for the syntax analysis.

What differentiates JavaCC from other parser generators that exist for
the Java language is that it creates source code in Java. This
facilitates the understanding and eliminates the need of having
dependencies in the code. JavaCC has also shown itself to have a much
better performance than other tools such as Another Tool For Language
Recognition (ANTLR), that requires a runtime library
\cite{javaccversusantlr}. ANTLR was our first choice of parser
generator, but it was soon discarded due to its very low performance.

JavaCC can be downloaded, unzipped and added to the PATH. It also has
a plugin for Eclipse. Figure \ref{fig.javaccex} exemplifies the flow
in JavaCC. Once installed, JavaCC processes your grammar defined in a file
with extension =.jj= using the command =javacc=. The whole grammar
is kept in this file and it is the only file that needs to be
modified. It is also possible to add Java code that has to be executed
during the parsing.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{How JavaCC works}
\centering
\includegraphics[width=\linewidth]{./img/javaccex.pdf}
\label{fig.javaccex}
\end{figure}
#+END_LaTeX

_Comments_:
- Missing figure, can't give my opinion on it

In Figure \ref{fig.javaccex} we can see an example of the processing
of a file named *MyGrammar.jj*, which results in seven files: the
parser in *MyGrammar.java*; the lexical analyser in
*MyGrammarTokenManager.java* and some useful constants in
*MyGrammarConstants.java*.  The other four files generated:
*Token.java*, *TokenMgrError.java*, *SimpleCharStream.java* and
*ParseException.java* are boilerplate files that can be reused within
parsers and are not affected by the grammar itself.  The corresponding
Java source code for the scanner and parser can be compiled as usual
with =javac=.

** JDBC and MySQL

The Java Database Connectivity (JDBC) API is a standard for
connectivity between Java and a range of relational databases
\cite{jdbc}. It comprises methods to query and update data, enabling
the Java language to interact with several Database Management Systems
(DBMS) in a standard manner. This API facilitates the migration from
one database tool to another and unbounds your application from a
DBMS.

The JDBC architecture, depicted in Figure \ref{fig.jdbcex}, consists
in two layers: JDBC API and JDBC Driver API. JDBC can support multiple
heterogeneous databeses \cite{jdbctut} by using drivers connected to
them. In the example of Figure \ref{fig.jdbcex}, we have an
application communicating with three different databases: A, B and C.
The JDBC Driver API manages the corresponding drivers to ensure that
the correct one is being used. The JDBC API layer, in turn,
administrates the communication between the application and the driver
manager. The JDBC API consists in classes and interfaces, such as
*DriverManager*, which makes a connection between requests from the
application and the proper database driver; *Connection*, containing
all the methods necessary to contact the database; *Statement*, that
creates objects that will be submited to the database; and
*ResultSet*, where the retrieved objects are placed.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Architecture of JDBC. [Inspired in \cite{jdbctut}]}
\centering
\includegraphics[width=.5\linewidth]{./img/jdbcex.pdf}
\label{fig.jdbcex}
\end{figure}
#+END_LaTeX

_Comment_
- Identify each "database" drawing with A B C, say that they are
  DB. Same for the corresponding JDBC drivers.

Among the possible DBMS that can be used in a Java application using
JDBC is the MySQL system, one of the most important open-source DBMS
in the market. It has been developed by Oracle and uses SQL language
as interface. To enable the use of MySQL with Java, Oracle provides a
driver for JDBC, as well as a native C library to allow developers to
embed SQL commands directly in the application's code.


** Entity-Relationship and Relational Models
\label{subsection.er_relational}

An Entity-Relationship (ER) model defines a database in a conceptual
view \cite{heuser}. This model can be represented by an ER Diagram
(ERD) and can be denoted by *schema*. It is based in the notion of
*entities*, which can be real-world objects that are easily
identifiable \cite{ertutorial}, and the *relationship* between
them. Figure \ref{fig.ermodelex} exemplifies a schema of a school
system where the people and places involved are represented. The
entities have a set of attributes, where one or more are defined as
the *identifier*, which uniquely identify an object of that entity. It
is also possible for a relationship to have attributes, like the
*address* attribute in Figure \ref{fig.ermodelex}. Besides, an entity
can derive other more specialized entities, which is called
*specialization*.

A relationship between entities *A* and *B* can have one of the
following patterns: *one-to-one*, where an object of the entity A can
be associated to only one of type B and vice versa; *one-to-many*,
which means that an instance of the entity A can be associated to more
than one entities of type B, but B entities can only relate to at most
one of type A; *many-to-many*, where one object from the A entity can
be associated to more than one entities of type B and vice
versa. These characteristics also apply to self-referencing relations,
where there is a relationship of an entity with itself. Besides, a
connection can be an *identifying relationship*, which means that the
relationship identifies an object. In Figure \ref{fig.ermodelex} we
can see the example of the relationship between a *City* and a
*State*, where we define that a state can have more than one city,
while a city belongs to only one state. Also, the state identifies a
city along with its name, since there can be other cities with the
same name but in different states. In these cases the entity is called
a *weak entity*.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Example of ER Model}
\centering
\includegraphics[width=\linewidth]{./img/ermodelex.pdf}
\label{fig.ermodelex}
\end{figure}
#+END_LaTeX

_Comment_:
- Figure improved a lot. Thanks. Unfortunately, text still looks like
  very small when comparing to the ordinary surrounding text. Can you
  print to see if it is readable? Maybe it's just a bad feeling from
  my side.

The ER Model is an overview of the structure of a database. To evolve
to the implementation, a translation to a Relational Model must be
performed. The ER model is a conceptual description of the database,
while the relational model is a logical representation
\cite{heuser}. Relational databases are based in the concept of
*tables* \cite{relationalmodel}, thus, the terminology used in this
step involves *tables*, *rows* (or *tuples*) and *columns*. The
identifier is called *primary key*. There is a set of rules to make
this translation, although sometimes it is necessary to adapt the
schema based on the user's needs.

The *entities* of the ER model become *tables* in the relational
model, while its attributes become the *columns* of the tables. Each
instance of an entity is a row and its identifier can be one or more
columns that compose the *primary key*. When there is an identifying
relationship, the weak entity attaches the identifier of the other
entity to its own primary key. In Figure \ref{fig.ermodelex}, the
*City* table has two columns as primary key: *stateName* and
*cityName*. A *one-to-one* relationship generates a merge of both
tables involved. *One-to-many* links adds an attribute in one of the
tables. The entity that can only be related to one of the instances of
the other receives the attribute, which is called *foreign key*. It
also absorbs the attributes of the relationship. In the example of
figure \ref{fig.ermodelex}, the table referencing the *School* entity
would have the *stateName* and *cityName* as foreign keys and
*address* as attribute. The foreign key is what preserves the link
between two entities. *Many-to-many* relationships have to be
represented by a separate table with the primary keys of both entities
involved, which also work as foreign keys. In our illustration, the
relationship between *Grade* and *Student* would become a table, with
*studentId* and *gradeId* as primary and foreign keys.

The translation of specializations can be made in two ways: one single
table for all of the hierarchy, where the primary key would be the
identifier of the most generic entity and there would be optional
columns; and one table for each specialized entity, where all of them
would have the identifier of the most generic entity composing the
primary key. In Figure \ref{fig.ermodelex}, the first case would
generate a single *Person* table, with *personId* as primary key and
*name*, *phone*, *studentId*, *course* and *salary* as attributes. In
the second option, *Student* and *Teacher* become tables, with
*personId* composing their primary key.

** Experimental Design

Experimental design, in the context of performance analysis, aims to
define a minimum number of experiments that collects the maximum
information necessary \cite{jain}. It also targets random variations
that could affect the results, guaranteeing that the number of tests
executed and the error margin calculated is sufficient to avoid
misleading conclusions.

There is a specific terminology used in experimental design. The term
*Response Variable* is the outcome of an experiment; *Factors* are all
of the variables that can have several different values affecting the
response variable, and *Levels* are the possible values that a factor
can assume. Also, the *Primary Factors* are the factors that need to
be quantified, *Secondary Factors* are the factors whose impacts in
the performance are irrelevant for the analysis, *Replication* is the
number of repetition of all or some experiments and *Design* is the
specification of total number of experiments based on factor level
combination and number of replications for each experiment. The
*Experimental Unit* is the entity used for the experiment, which could
be a computer, for example, and *Interaction* is when the levels of a
fator affect the results of other factor.

There are several types of experimental design modeling. One of them
is the full factorial design, which consists in evaluating every
possible combination at all levels of all factors. With this type of
design, it is possible to measure factors with multiple numbers of
levels. The advantage of this model is that every possible combination
is measured, generating richer results. However, depending on the
number of factors, levels and replications, it may generate too many
experiments, which can cost a lot of time. Therefore, when using this
technique, it is important to weight the relevance of each factor and
level to generate an appropriate and accurate design. To calculate the
total size of the sample you multiply the numbers of levels of the
factors and the number of replications. For example, a design with a
three-level factor, a two-level factor and 20 replications would have
120 experiments (the result of $3*2*20$).

When there are too many factors and levels, it may not be possible to
use the full factorial design. In these cases, one can use a
fractional factorial design, which covers just a fraction of the full
factorial design. In this type of experiment, a carefully chosen
subset of factors and levels is taken into consideration, based on the
most important features the analyser wants to test. Although it saves
time and expenses, the results provide less information.


** The R language

R is a language for statistical computing and graphics generation. It
can be very easily extended, by creating and using packages. With R,
it is possible to create full factorial or fractional designs using
the *DoE.base* package. It contains the class *design* with several
accessor functions to create different types of design. One particular
important function is the *fac.design*, which creates full factorial
designs with an arbitrary numbers of levels. The function receives
several arguments, including number of factors, levels and
replication. The usage of the function is the following:
#+BEGIN_LaTeX
\begin{lstlisting}
require(DoE.base);
fac.design(
  nfactors=2,
  replications=30,
  repeat.only=FALSE,
  blocks=1,
  randomize=TRUE,
  seed=10373,
  nlevels=(3,6),
  factor.names= list(
                input=c("small", "medium", "big"),
                batch=c("A", "B", "C", "D", "E", "F")));
\end{lstlisting}
#+END_LaTeX
where =nfactors= represents the number of factors, *replications* is
the number of replications, *repeat.only* tells if the replications of
each run are grouped together, *blocks* is a prime-number telling in
how many blocks the experiment is subdivided, *randomize* informs the
design is randomized, *seed* is the optional seed for the
randomization, *nlevels* is a vector with the number of levels for
each factor and *factor.names*: a list of vectors with factor levels.
This example is one of the designs used for the performance evaluation
in Chapter \ref{chapter.performance}.

* The PajeNG Framework
\label{chapter.paje}

The Pajé Visualization Tool is an implementation to display the
execution behavior of parallel and distributed programs. It reads
information from trace files that describe the important events during
the execution of a program and replays them through simulation.  It
has been developed to simulate trace files in the Pajé Trace File
Format, thus, it is important to understand how the Pajé trace files
are composed. Section \ref{section.pajeformat} describes this format
and all entity types it contains. The next section describes the new
generation of the Pajé Visualization Tool, the PajeNG, focusing on the
*libpaje* module, which is where the core simulation is performed.
 
** The Pajé Trace File Format
\label{section.pajeformat}

The Pajé Trace File Format \cite{pajetracefile} is a textual and
generic pattern that describes the behaviour of parallel and
distributed programs. The Pajé format describes five types of
entities: containers, states, events, variables and links. Each entity
is always associated to a container, even the containers themselves. A
*container* can be any hardware or software entity, such as a
processor, a thread, a network link, etc. It is the only Pajé object
that holds other objects, including containers, which makes it the
main component to define a type hierarchy. A *state* is used to
describe periods of time where a container stays at the same state,
like a thread that is blocked, for example. It always has a beginning
and an ending timestamps. An *event* has only one timestamp, and can
be anything noteworthy to be uniquely identified. A *variable* entity
represents the progression of a variable's value along time. It is
represented by an object with a value and two timestamps, beginning
and end, indicating how long the variable had that specific value. A
*link* represents a relationship between two containers, such as a
communication between processes. It contains two timestamps specifying
the beginning and the end of the communication. A Pajé trace file is
divided in two segments: event definition and timestamped events. A
brief description of these sections is provided below. For details and
an example of an event definition, as well as a full list of events
refer to Appendix \ref{ap.pajeformat}.

*** Header section: events definition

The first part of a trace file describes all of the possible events of
the trace. This part is composed by a block where the first line
contains the name of the event, like *PajeDefineContainerType*, for
example, followed by a unique identifier. The identifier is an integer
and will be used later by the events to determine the type of event in
question. After, there is a set of fields, one in each line. Each
field comprises a name, and a type. The type of a filed can be a
string, double, int, date, hex or color.

*** Body section: timestamped events
\label{subsection.events} 

After the events definition, the events themselves are described, one
in each line. Every event starts with its identifying number, which
was defined previously, followed by the fields separated by space or
tab. Before the entities, such as states or links, can be created, a
hierarchy of types and containers must be defined and containers need
to be instantiated, since every entity belongs to a container. There
are sets of events associated to each kind of entity described above,
besides the events that define entity types.

The Pajé objects are organized in two separated hierarchies: types and
entities. These hierarchies are specific for each trace file, although
it can be repeated in traces with the same scenario. In the structure
of the trace file, the type hierarchy comes just after the event
definition. There, each type of the program is defined and one of the
fields is always the parent type. Each entity is always associated to
a type and they must follow the same precedence as the types
definition. For example, as shown in Figure \ref{fig.hierarchyex}, if
the container C1, of type T1, is the parent of the container C2, of
type T2, the type T2 must be child of T1 in the type tree. The root
type is always the number $0$. The difference between both hierarchies
relies on the number of nodes: while the type hierarchy has only a
few, the entities hierarchy may have millions depending on the number
of containers in the trace.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Example of ER Model}
\centering
\includegraphics[width=\linewidth]{./img/hierarchyex.pdf}
\label{fig.hierarchyex}
\end{figure}
#+END_LaTeX

Type definition events don't have a timestamp field and can occur at
anytime in a trace file, as long as the type is not used before its
definition. It is more common to have all the types defined in the
beginning. The events associated to the containers are timestamped and
can create or destroy instances during the trace file. A container
cannot be referenced after it was destroyed. Variables can be set at a
specific timestamp and have its value changed throughout the
simulation by addition and subtraction events. The value of a variable
is a double precision floating-point number, which is different from
the values of the other entities. A variable must be set before
changes to its value can be made.

** PajeNG Tools and Simulation Library 
\label{section.pajeng}

The PajeNG implementation is the new generation of the Pajé
Visualization Tool \cite{pajeng}. It was developed in C++ and follows
the same architecture as the original Pajé, written in Objective-C. It
comprises a library containing the core of the simulation (*libpaje*),
a space-time visualization tool and some auxiliary tools to manage the
trace files. The base for the implementation of this project was the
*libpaje* library.

The library, represented in Figure \ref{fig.pajeparco} has three main
components forming a pipeline that results in complete simulated
entities. These components are: *FileReader*, *EventDecoder* and
*PajeSimulator*. First, the *FileReader* reads a chunk of data from
the trace file and puts it in memory. Then, the *EventDecoder* breaks
it into events identifying, line by line, the event's fields and
creating an object with all the necessary information. Last, the
*PajeSimulator* receives this event object and addresses to the proper
simulation. 

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{PajeNG Architecture [inspired in \cite{kergommeaux2000paje}]}
\centering
\includegraphics[width=\linewidth]{./img/pajeparco.pdf}
\label{fig.pajeparco}
\end{figure}
#+END_LaTeX

Pajé was idealized to be extensible, specially in terms of creating
new types of events. Actually, the Pajé format itself is very
expandable, which makes it necessary to build a simulator
accordingly. This flexibility is implemented by a class hierarchy,
going from the most general, containing the basic fields common to
every type and entity, to the most specific. Besides, the PajeNG tool
supports extra fields in the events, which allows the simulation of
extended entities. There are three main class hierarchies that are
particularly important in this objective: one for events, one for
types and one for entities. With this modular implementation, it is
relatively easy to add a new type of event or entity and integrate it
with the rest of the code.

*** Class hierarchy for Paje events

An event object is what is passed as an argument to the simulator so
that it can be processed. Therefore, it must contain all of the
necessary information for the simulation. The first object created
when a trace file is being parsed is of type *PajeTraceEvent*, which
is a class containing all the fields read by the *EventDecoder*. As
depicted in Figure \ref{fig.eventsHierarchy}, the event hierarchy
starts with a simple *PajeEvent* class. This class has a trace event
object, a container, a type and a timestamp. The immediate childs of
PajeEvent are: *PajeCategorizedEvent*, *PajeVariableEvent* and
*PajeDestroyContainerEvent*. The variable event is the parent of the
specific events for variables, which are set, add and subtract. A
categorized event is characterized by having a *PajeValue* associated
to it, thus, *PajeStateEvent*, *PajeEventEvent*, *PajeLinkEvent*, and
their respective childs inherit from it.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Events class hierarchy}
\centering
\includegraphics[width=\linewidth]{./img/eventsHierarchy.pdf}
\label{fig.eventsHierarchy}
\end{figure}
#+END_LaTeX

*** Class hierarchy for the Paje types

Figure \ref{fig.typesHierarchy} portrays the type hierarchy, where the
first element is the *PajeType*. It has a name, an alias and a parent
type, which is also a PajeType. These fields are the ones common to
all the type definition events described in section
\ref{section.pajeformat}. The immediate childs of this class are:
*PajeCategorizedType*, *PajeVariableType* and *PajeContainerType*. As
the events, the categorized types are associated to a value, hence,
the PajeCategorizedType has a PajeValue field and methods to
manipulate it. Its childs are the *PajeStateType*, *PajeEventType* and
*PajeLinkType*.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Events class hierarchy}
\centering
\includegraphics[width=.6
\linewidth]{./img/typesHierarchy.pdf}
\label{fig.typesHierarchy}
\end{figure}
#+END_LaTeX

*** Class hierarchy for the Paje entities

As demonstrated in Figure \ref{fig.entitiesHierarchy}, the
*PajeEntity* is the first node of the entities tree. It originates a
*PajeSingleTimedEntity* class, that describes entities with one single
timestamp. The *PajeUserEvent* is the only entity with this
characteristic, but it is possible to add, in the future, more
entities with just one timestamp. The *PajeDoubleTimedEntity* inherits
from this class and represents entities with start and end
timestamps. Like the other hierarchies, the valued entities are
grouped together so a *PajeValuedEntity* is a child of the double
timed entity, having *PajeUserState* and *PajeUserLink* as
descendents. The double timed entity also has *PajeUserVariable* and
*PajeNamedEntity* as childs. A *PajeContainer* inherits from the named
entity.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Entities class hierarchy}
\centering
\includegraphics[width=\linewidth]{./img/entitiesHierarchy.pdf}
\label{fig.entitiesHierarchy}
\end{figure}
#+END_LaTeX

*** The core simulator

All the simulation is performed in two classes: *PajeSimulator* and
*PajeContainer*. A PajeSimulator object is instantiated in the
beginning of the program and incorporates all the event processing of
the simulation. The type definitions, container creations and entity
value declarations are completed and stored in the PajeSimulator
object. Every time there is an event of type *PajeCreateContainer*, a
PajeContainer object is instantiated. All other events are always
associated to a container, thus, they will be simulated in the
appropriate container instance. The PajeContainer object will keep the
entities until the program finishes. Since all the data from the
simulation is kept in memory, the end timestamp is used to signal that
an entity no longer can be referred.

The PajeSimulator class lists every type declared and container
created throughout the simulation by using map structures (=typeMap=
and =contMap=) with the name or alias as key. There is always a
pointer to the root type and another to the root container initialized
in the beginning of the program.  The simulator contains one method
for each type of event described in Appendix \ref{ap.events}, which
perform all the validations, besides the processing itself. Whenever
there is an event that defines a type the entity generated is added to
the =typeMap=.  =contMap= and the proper method of the container
object is called.

The PajeContainer class also uses map structures to store all the
entities that are related to it including other containers. Besides
one general structure that lists all of the objects related to the
container (=entities=), there are auxiliar structures for some
specific types, such as states (=stackStates=) and links
(=pendingLinks=). There is some redundancy between =entities= and the
other constructions but, since the objects are pointers, the changes
made in one structure are reflected in the other ones.

Every event that pushes a state will add a state entity to the end of
the =stackStates= stack, while every pop state event will "remove" the
last state in the vector by setting its end time. The simulation keeps
track of the pending communication links and fails if a container is
destroyed, or the simulation ends, before all the links are
completed. The PajeContainer class contains a method for each event
that is associated to a container, adding and removing entities of
these structures listed above.

** Current Issues Regarding PajeNG
\label{sec.pajeng_issues}

The focus of the Pajé implementation is to allow the user to extend
the Pajé format and adapt the simulator to it. Its support for extra
fields allows the inclusion of different descriptions for the events
and its modularity facilitates the integration of new
classes. Altering or adding simulation behavior can be done by
modifying only the =PajeSimulator= and =PajeContainer= classes.

Although complying with its goal of extensibility in terms of
expanding the Pajé format, we identified three main issues in the
current implementation of PajeNG: little flexibility in the
manipulation of data, lack of partial outcomes, and ephemeral
results. When the entities are already simulated, a deeper
understanding of the code structure is necessary if one wants to
define another way of handling the results. Also, the user needs to
manage a full set of entities, since there is no flexibility of
discarding data that is not relevant. The second issue relies on the
fact that the *PajeSimulator* instance maintains all of the simulated
objects in memory. If a user wants to see the resulted entities during
the simulation, he would need to get into the *PajeSimulator* code to
make the necessary changes. Technically, since all the results are
stored in memory, it would be simple to add a new functionality, but
it is limited to the manipulation of the whole set of results, not
each entity separately. Last, the results kept in memory during
simulation are discarded at the end, which implies in executing all
the simulation again if a trace file needs to be revisited.

Considering the presented issues, an extensible simulator written in
Java was developed. The intention of this proposal is to make the
simulation core more transparent for the performance analyst providing
the created entities in a way that he can manipulate them without
looking to the rest of the implementation. The program uses the
concept of plugins that attached to every type of event. The simulator
itself addresses the first issue presented, while the creation of new
plugins provide a possible solution to the other two. The details of
this novel approach, developed in our work, are detailed in the next
chapter.

* Aiyra - a Java-based simulator for Paje trace files
\label{chapter.aiyra}

Aiyra is an extensible simulator written in Java that reads trace
files in the Pajé format and, instead of storing the results in
memory, forwards every created entity to a common place where it can
be manipulated freely. The architecture of the implementation,
characterized in Figure \ref{fig.aiyraArchitecture}, contains three
packages: *controller*, *simulator core* and *plugin*. Every event of
a trace file always goes through all packages. First, the trace
file in the input is read by the parser, where a trace event object is
created. This instance contains the type of event in question and the
field values. In the example of Figure \ref{fig.aiyraArchitecture},
the event read is the creation of a container of type *P* with alias
*P1* and parent *0*, which is root. Then, the simulator receives this
object and executes the simulation based on the event type. The
simulation always generates an entity, even if incomplete. In Figure
\ref{fig.aiyraArchitecture}, a *PajeContainer* is created without an
ending timestamp. Finally, this new entity is sent to the plugin,
which contains specific entry points for every different kind of
entity.


#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Aiyra Architecture}
\centering
\includegraphics[width=\linewidth]{./img/aiyraArchitecture.pdf}
\label{fig.aiyraArchitecture}
\end{figure}
#+END_LaTeX

_Comment_:
- For some reason, there is a lot of vertical space just below Figure
  4.1 (aiyra arch.). Please remote it since it looks strange. Perhaps
  it is just a bounding box issue with your PNG.

The program receives arguments from the user in its execution. The
*filename* option (=-f=) is the only mandatory one, which indicates
what is the trace file to be simulated. There are other two general
options: *comment* (=-m=), a comment about the file; and *plugin*
(=-p=), which indicates which plugin will be used in the
simulation. The details about the already implemented plugins are 
presented in chapter \ref{chapter.plugins} and a step-by-step 
execution of Aiyra can be found in Appendix \ref{ap.aiyraexecute}. The
following subsections detail each one of the packages.

** The controller: option handling and JavaCC


The controller package is the entry point of the program, thus, it
also handles the arguments passed by the user. For this processing, an
external library \cite{optionhandler} was used. The arguments handling
is centralized in one single class, *OptionsHandler*, to facilitate
the inclusion of new ones. The Paje file format (see Section
\ref{section.pajeformat}) is parsed by a grammar written using the
JavaCC syntax. The file *PajeGrammar.jj* containing all the grammar
rules of the format is processed by the Java Compiler Compiler
(JavaCC) to generate the parser.  Each event definition is stored in
an array, while the events are simulated as soon as they are obtained
from the trace.

The controller package is composed by all of the JavaCC files
described in Section \ref{section.javacc} and the OptionsHandler
class. The generated class *PajeGrammar.java* contains, besides the
parsing component, all the necessary Java code for the program to run,
such as the initialization of the simulator object, where all of the
simulation takes place. Every time an event is identified, the
simulator instance, which is the entry point of the simulator core
package, is called to simulate that event. The next section describes the
simulator core package. For details about the OptionsHandler class and
the complete grammar created for the Pajé Format refer to Appendix
\ref{ap.optionshandler} and \ref{ap.grammar}.

** Aiyra's core simulator

Aiyra's core simulator, depicted in Figure \ref{fig.aiyraCore},
follows the exact same structure of the *PajeNG* implementation
described in section \ref{section.pajeng}. Every event read by the
parser and sent to the core by the controller goes through the
*PajeSimulator* component, which is then forwarded to a
*PajeContainer* if necessary. In the example of Figure
\ref{fig.aiyraCore}, the simulator receives a *PajePopStateEvent*,
that is validated in the *PajeSimulator*, forwarded to the *C1*
container, and then dispatched to the proper instrumentation
point. The class hierarchy follows the same organization as the
PajeNG, thus, it is equally expandable in terms of creating new types
of events or entities. However, it does not support extra fields in
the events since the focus on the implementation was extending the
output of the simulator. This makes our solution more limited for
changes in the Pajé Trace file, which happens not very often. Despite
that, it would be simple to adjust it since changes do not affect the
implementation of the plugins.

  _Comments_:
- A figure explaining the behavior of the PajeSimulator and its
  relationship with the PajeContainer would be nice. I think that from
  here on you describe all the specific details of the implementation
  without giving the reader a proper preparation stating how the
  simulator actually _works_. Note that it is important to have an
  abstract understanding of the behavior before diving in details. If
  you start with details, nothing can be understood.
- Input on the left; output on the right: on the center, the
  PajeSimulator and on its right the multiple PajeContainers. You can
  use a specific example with three containers and very few
  timestamped events regarding states, for example. SEE DESCRIPTION ABOVE.
- I just figured out the existence of Figure \ref{fig.aiyraCore}. It
  is exactly that, but focused on an example regarding the behavior of
  your simulator (you can even use a component to represent your
  grammar) in particular. You would have here another figure then.

Every entity generated is represented by an object with attributes
representing its fields. The class hierarchy of the entities is the
same as the one presented in Figure \ref{fig.entitiesHierarchy}. All
of the types derive from the *PajeType* class, which contains *alias*,
*name*, *depth*, and *parent*, a *PajeType* as well, as attributes. It
also provides the =getNature()= method, to identify which entity this
type describes. The nature is an enumeration and can assume
*ContainerType*, *StateType*, *EventType*, *LinkType* or
*VariableType*. The *PajeVariableType* adds a *PajeColor* to its
attributes, which is an object with the values for red (=r=), green
(=g=), blue(=b=) and alpha(=a=). The *PajeLinkType*, in turn, includes
*startType* and *endType*, which stand for the type of the start and
end containers of the communication. A value is represented by a
*PajeValue* class, with *name*, *alias*, *type* and *color* as
attributes.

A container object (*PajeContainer*) has an *alias*, *name*, *type*
and *parent* (another *PajeContainer*), besides the structures to
store the entities related to it, as described in section
\ref{section.pajeng}. Since the container class is a child of the
*PajeDoubleTimedEntity*, it also has a *startTime* and an
*endTime*. All other entities are associated to a container and a
type, thus, they have a *container* and a *type* fields. The event
entity (*PajeUserEvent*) is the only one that derives from
*PajeSingleTimedEntity*, hence, it has a unique timestamp named
*time*. Also, it has a *value* attribute, which is a *PajeValue*. The
other valued entities, *PajeUserState* and *PajeUserLink*, inherit the
*PajeValue* attribute from the *PajeValuedEntity* class. A
*PajeUserVariable* object also has a *value* attribute but, unlike
events, states and links, it is a double number. The *PajeUserLink*
has a string that defines the *key* and start and end containers
identified by *startContainer* and *endContainer*.

Every trace event simulation has an instrumentation point, which
dispatches the entity objects generated to the plugin package. These
points are either in the *PajeSimulator* or in the *PajeContainer*, as
illustrated in figure \ref{fig.aiyraCore}. In the *PajeSimulator* are
the outputs regarding the definition of types and values and the
creation of containers. Although in this point the containers are not
complete objects, since they do not have ending timestamp or the
related entities, they are forwarded anyway with the alias and type
information. The *PajeContainer* is in charge of dispatching to the
plugin the instances related to it, which involve the states, events,
links and variables. It also may send unfinished objects. When there
is a *PajeDestroyContainerEvent*, the container object is sent again,
now complete with an ending timestamp.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Aiyra's Core Architecture}
\centering
\includegraphics[width=\linewidth]{./img/aiyraCore.png}
\label{fig.aiyraCore}
\end{figure}
#+END_LaTeX

_Comment_
- This figure also has a large white margin on the bottom. Remote it
  please.

The choice of creating an instrumentation point for each trace event
is due to the intention of covering all of the different needs of the
user. One may need the container name before it can process the
entities related to it, for example, which cannot be achieved by
receiving the container only when it is completed. Or else, may be a
situation where the push state events need to be measured, instead of
the pop state events, where the entities are finished. Since we cannot
predict all of the use cases, it is desirable to have a broad
approach. A full list of the plugin entrances and the information
received in each one is presented in the next section.


** The plugin package
\label{section.plugin}

The plugin package is a common place where all entities created
throughout simulation are sent. It has sets of entry points specific
for each type of entity and event. The entrances consist in:
*newType*, *newValue*, *startLink*, *endLink*, *newCompleteLink*,
*newCreatedContainer*, *destroyedContainer*, *setState*, *pushState*,
*popState*, *resetState*, *setVar*, *updateVar*, and *newEvent*. The
details of each point are presented later in this section. The plugin
package is composed by an abstract class, the *PajePlugin*, with one
method for each instrumentation point. It also contains a method
called *finish* where the user can perform some concluding actions
after the simulation is completed. To create a new plugin, the user
just needs to extend the *PajePlugin* class and override its
methods. It is also possible to extend another existing plugin, if the
differences are small and not worth of a new class implementation.

The entrances of the plugins comprise the definition of types and
values, the creation of containers, and the formation and completion
of new entities. The *newType* entry point is a unique entrance for
when a type of any kind is defined, having the *PajeType* object as
argument. The =getNature()= method can be used to identify the exact
type. The *newValue* method receives every *PajeValue* created.

When a container is created in the simulation, the instance is
forwarded to the *newCreatedContainer* entry point, with the end
timestamp set to $-1$. Whenever a method receives an entity that is
not completed yet, the end timestamp will be $-1$. The
*destroyedContainer* method takes in a complete container that has
just been destroyed. Most of the entities are removed during
simulation, but the destroyed container may have some remaining ones
that could not be excluded, such as variables.

The link entry points receive *PajeUserLink* objects. In the
*startLink*, the end time and end container of the communication link
are unknown, while in the *endLink*, instance has the end point of the
link but not the start. The *newCompleteLink* method takes in a link
entity with beginning and end. Anytime a variable is set or updated,
there are three *PajeUserVariable* entities sent to the plugin: the
*first*, which contains the first value of the variable; the *last*,
which is the one immediately before the variable in question; and the
new variable which is not completed yet (*newVar*). The aditions and
subtractions are sent to the same point (*updateVar*). Since the
previous variable objects are necessary to generate the new value,
they are not removed from memory during simulation. The set, push and
pop state instrumentation points all receive a *PajeUserState*. The
only one with an entity with beginning and end timestamps is the
*popState*. The *PajeUserEvent* objects are sent to the *newEvent*
function.

To validate the concept of the plugins and its entry points, three
plugins were created: *PajeNullPlugin*, *PajeDumpPlugin* and
*PajeInsertDBPlugin*. Their implementation is described in the next
chapter.
  
* Aiyra's Standard Plugins
\label{chapter.plugins} 

_Comment_
- about previous and this chapter.
- perhaps in the "plugin" section (or even before) of previous chapter
  you could introduce a figure with a standard plugin visual
  representation.
- Then here, for each plugin, you would copy that standard plugin
  visual representation and keep only things that are part of that
  specific plugin. It would be very easy to understand, and you'd have
  a figure for each plugin below.

To address traditional uses of Paje trace files, we have implemented
three plugins for the Aiyra framework: the *PajeDumpPlugin*, the
*PajeInsertDBPlugin*, and the *PajeNullPlugin*. The first one is used to
match the behavior of the existing =pj_dump= tool but without the issues
we have mentioned in Section \ref{sec.pajeng_issues}; the second one
can be used to insert the trace file in a relationa database, allowing
the user to use SQL commands to inspect simulated traces; and finally,
the third can be used to evaluate the Aiyra's performance for any kind
of input. We detail each of them in the following, from the one that
presents the lowest to the highest complexity.

** Paje Null Plugin

The *PajeNullPlugin* is the default plugin option. It does not make
any treatment to the data so the objects are simply discarded. The
utility of this plugin relies on the need to verify the performance of
the simulation itself, whithout the interference of data
manipulation. Since the main goal of this proposal is to deattach the
core simulation from the data handling, it is desirable to be able to
execute the core alone.

** Paje Dump Plugin

The Dump plugin performs the same action as the *pj_dump* tool, which
dumps to the standard output the entities generated by the
simulator. The implementation consists in inserting a =print= function
in each instrumentation point that receives a complete entity. These
points are: *destroyContainer*, *popState*, *newCompletedLink*, and
*newEvent*. When it is a destroyed container, it is necessary to
iterate over the entities left in the container. The variables printed
in the destruction of the container, since they are not removed during
simulation.

The difference between the *PajeDumpPlugin* and the *pj_dump* tool is
that the first one outputs the information as soon as the entity is
completed. The *pj_dump*, in turn, keeps everything in memory before
dumping it all at once. With this approach, it is possible to solve
the issue regarding the need to wait for the program to end to have
the results.

This plugin can be called with the argument =PajeDump= in the =-p=
option and adds a new argument (=-l=) that can group together a
certain number of entities before dumping it. The option receives an
integer as parameter defining the number of lines it should reach
before dumping the entities. This provides a little more flexibility
for the user and may improve the performance, since the printing
function of Java costs time. For it to be possible, a =StringBuilder=
is used as a buffer keeping all of the output until it reaches the
number of lines desired.

** Paje Insert Database Plugin

The *PajeInsertDBPlugin* saves in a relational database all the
results of the simulation. For the implementation, the JDBC API was
used to make a connection with the MySQL database. The schema used was
specially designed for the Pajé format and is presented in the next
subsections. This plugin allows the user to save data from multiple
files in the same database.

The plugin can be used by specifying =mysql= as argument for the =-p=
option. It is necessary to have a MySQL connection and a database with
the correct schema. To specify the server of the connection, there is
the option =-s=. It is also possible to inform a username (=-u=) and a
password (=-pwd=). The default for these options is: *localhost*,
*root* and *root*, respectively.

The following entry points were used in the *PajeInsertDBPlugin*:
*newType*, *newValue*, *newCreatedContainer*, *destroyedContainer*,
*popState*, *newCompleteLink*, *updateVar* and *newEvent*. Types,
values and containers are inserted in the database as soon as they are
created due to the dependency of other entities on these ones. When a
container is destroyed, its *endTime* is updated in the database.

The first approach of this implementation consisted in inserting the
entities in the database at the time they were created. Database
accesses cost time and, by executing some preliminary tests, we
observed a very bad performance, that took an unnaceptable amount of
time (over $24$ hours for 1 Gigabyte trace files). To solve this
problem, we used the mechanism of *batches* provided by JDBC, which
sends a block of queries all at once, reducing the communication
overhead. This functionality is optional and can be included by adding
the (=-batch=) option with an integer as argument. This number will
define how many queries it will store before inserting a batch in the
database. This is only applicable to states, events, links and
variables, since types, values and containers are immediately
inserted. performance analysis for different sizes of batch is
presented in the next chapter.

To create a relational database for the Pajé format, first, we created
an entity-relationship model that is described in the subsection
below.

*** Entity-Relationship Model

The entity-relationship (ER) model, illustrated in Figure
\ref{fig.ermodel}, contains one entity for each type of Pajé
object. Also, to support multiple files, there is a *file* entity,
which has the *name*, a *comment* and the *date* as attributes, as
well as a *file_id*. The *Type* and *Container* entities have an
identifying relationship with *file*, which means that the file id is
part of their identifier. The relationship is one-to-many, since a
file can have multiple types and containers.

The *Type* entity has *alias*, composing the identifier, *name* and
*depth* as attributes. It also contains a self-referencing one-to-many
relationship to indicate the *parent* type, as a type can have
multiple children. It is associated to a *Value* entity, which
describes the *PajeValue* class, with *alias*, *name*, *type*
(identifying relation) and *color*. Link and variable types have
exclusive attributes that are not common to all types, thus, both are
specializations of *Type*. *LinkType* adds a relationship with itself
to represent a the start and end. This is a many-to-many relationship
because the types can be the start and end to various
communications. The *VariableType* has a color attribute.

The *Container* entity has an identifying one-to-many relashionship
with *Type*, as well as every other entity, since all of them are
classified by a type. Containers have the same attributes as types,
including the *parent* one-to-many relation. All of the entities that
are related to a container, have an identifying one-to-many relation
with *Container* entity. *State* has *startTime* and *endTime*
attributes, where the first is identifier. *Link* has two one-to-many
relationships with *Container*, one for *startContainer* and one for
*endContainer*. A *Variable* entity contains the *Time* attribute, as
well as an *updateTime* in the relation with *Container*. Also, this
relation has a *value* attribute. The *Event* entity has a *time*
field.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{ER Model for the Pajé format}
\centering
\includegraphics[width=\linewidth]{./img/ermodel.png}
\label{fig.ermodel}
\end{figure}
#+END_LaTeX

_Comment_
- You should take extra care with this figure. Reorganize.

*** Relational Model


A translation to a logical model was made after the creation of the
conceptual model. In this conversion, besides applying the universally
known rules presented in Chapter \ref{chapter.basic_concepts}, we
considered the usability of the schema, analysing the common requests
made in the Pajé data. This reflection is a usual part of the process,
where the needs of the client are contemplated.

The entities defined in the ER Model all became tables. For the *Type*
specialization, we used the first option presented in Section
\ref{subsection.er_relational}, combining everything in a single table
with the following fields: *file_id*, *alias*, *name*, *depth*,
*parent_type_alias*, *start_link_type*, *end_link_type* and
*color*. *File_id*, inherited from the identifying relation with
*File*, and *alias* compose the primary key. The self-referencing
relationships are described as foreign keys in their tables.  The
entities associated to the container all have at least three foreign
keys that are also identifiers: *type_alias*, *container_alias* and
*file_id*. Since the *Link* entity has a unique key, its two foreign
keys from *Container* don't belong to the identifier.

In our ER Model, the value is only associated to the *Type*, thus, if
one wants to know the value of a state, for example, it needs to first
get its type, then, go to *Type* table to retrieve the value. Since it
is desirable to easily get an entity's value, we added a relationship
between the valued entities (*State*, *Link* and *Variable*) with
*Value*. *value_alias* is an identifying foreign key for all, except
*Link*, where the identifier consists only in the *key*, *type* and
*file_id*. With the conceptual model of the *Variable* entity, it is
required to retrieve two rows if one needs to know the beginning and
ending timestamps of one entity. Since this information is very
important, we changed the *Variable* table for the tuples to
explicitly have *startTime* and *endTime*.


* Performance Evaluation
\label{chapter.performance}

An evaluation of Aiyra's performance was made to have concrete
conclusions about the outcome of this proposal. Two main tests were
executed: a comparison between Aiyra and PajeNG and an analysis of the
impact of different batch sizes in the *PajeInsertDBPlugin*. Since
Aiyra is strongly based in the PajeNG implementation, it is valid to
examine if the modifications and language transition have brought
significant performance impact on the simulation. The plugin that
inserts the data in a MySQL database is the only one that brings an
extremely different functionality to the program, hence, it was chosen
to be studied. As it involves the connection with an external tool,
the analysis of its performance and the study of the most efficient
use of it is very important.

We created full factorial experimental designs, using the R language
with the *DoE.base* package, to define the tests to be performed. The
package generates a Comma-Separated Values (*CSV)* file with one column for each factor. Each row
of the file represents each possible combination of the different levels
and multiplies it by the number of replications. We created *bash*
scripts to execute the experiments of the design generating another
*CSV* sheet including the response variables defined for the
experiments. The details about the factors and levels for each test
are described in the next section. The remainder of this chapter
comprises the analysis results.

** Methodology

The experiments are performed in three different machines: *luiza*,
with a Mac OSX environment, *guarani*, and *orion1*, both running
Linux. The details about the experimental platforms are described in Table
\ref{tab.machines}. We have created three input trace files with
different sizes identified by *small*, *medium*, and *big*. The sizes for
each of these cases are
128 Kilobytes, 128 Megabytes, and 1 Gigabytes, respectively.

#+BEGIN_LaTeX
\begin{table}[!htb]
\caption{Experimental Units description.}
\label{tab.machines}
\centering
\begin{tabularx}{\linewidth}{lXXX}\toprule
                         &   {\bf Luiza}         & {\bf Orion1}         & {\bf Guarani}    \\\toprule
Processor                &  Intel Core i7        & Xeon E5-2630         & Intel Core i5-2400   \\
CPU(s)                   &  1                    & 24                   & 4       \\
Cores per CPU            &  4                    & 6                    & 4             \\
Max. Freq.               &  2.7 GHz              & 2.30GHz              & 3.10GHz       \\
L1 Cache                 & 32/32KBytes           & 32/32KBytes          & 32/32KBytes  \\     
L2 Cache                 & 256KBytes             & 256KBytes            & 256KBytes    \\
L3 Cache                 & 6MBytes               & 6MBytes              & 6MBytes         \\
Memory                   & 16GBytes              & 32GBytes             & 20GBytes      \\\midrule
OS                       & OSX 10.10.5           & Ubuntu 12.04.5       & Debian 4.3.5-1 \\
\bottomrule\end{tabularx}
\end{table}
#+END_LaTeX

_Comment_:
- Are you sure L1, L2 and L3 cache sizes are the same for all of them?
- =Orion1= has only 2 CPUs, each one with 6 cores
- =guarani= has only 1 CPU with 4 cores.

*** Aiyra and PajeNG Comparison Methodology

This experiment evaluates the performance of Aiyra using the
*PajeNullPlugin* against two versions of the *pj_dump* tool (*pj* and
*pjflex)*, both part of PajeNG. The difference between the
=pj_dump= versions is in the reading of the
trace file: while the first (*pj*) uses the standard C++ parsing, the
second (*pjflex*) uses a scanner and parser generator (based on the
standard *flex* and *bison* from GNU). The
executions of the *pj_dump* tool received =--quiet= as a parameter to
avoid the actual dumping of the information in the standard output,
since we only need the execution time to carry out the comparison.
It is important to highlight that Aiyra does not perform any action
in the resulted entities and discards all of them.

Concerning the experimental design, two factors are chosen: *input* and
*version*. The first assumed the values *small*, *medium*, and
*big*. The second, *aiyra*, *pj* and *pjflex*. The number of
replications chosen was $30$. This value was selected after a few test
experiments where we noticed very little variability. As the
executions take a significant amount time, $30$ repetitions is enough
to have reliable results. Since we have two factors, each with three
levels, we have a total of $270$ experiments (the product of
$3*3*30$). The outcome of this experiment is the *execution* time for
each combination of input and version. This design was run in each one
of the platforms, thus, we had three files each with $270$ rows.

(header of the design?)

*** PajeInsertDBPlugin evaluation

The *PajeInsertDBPlugin* provides an option for the user to define a
batch size for the insertion in the database. The size defines the
number of entities to be inserted at once. This means that the queries
are stored in a buffer until a counter reaches the specified
value. Although this approach reduces the execution time, compared to
the first attempt described in Chapter \ref{chapter.plugins}, it
occupies a significant amount of memory. Our evaluation aims to define
what is the best choice of batch size for different scenarios.

For this experiment we used the same experimental units as the first
one, but we added a fourth experiment which consists in the remote
access between *guarani* and *orion1*. In the experiment, we had the
simulator running in *guarani* accessing the database in
*orion1*. Figure \ref{fig.infnetwork} represents the network
connecting the machines. Both are placed in _*INF em ingles ou
portugues? e ufrgs?*_, where the bandwidth is 100Mb/s. There is one
switch between both endpoints, which is what limits the network speed.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{ER Model for the Pajé format}
\centering
\includegraphics[width=\linewidth]{./img/infnetwork.pdf}
\label{fig.infnetwork}
\end{figure}
#+END_LaTeX

_Comment_:
- Wrong caption (pay attention to this please)
  - It is better if made right from the start (to avoid finalization problems)

The factors for this evaluation consist in the *input*, the same as
the ones described above, and *batch*, which assumes six different
values. The *batch* factor consists in the size of the batch to be
ineserted in the database. The number is not fixed and varies among
the different input sizes. The levels are classified from *A* to *F*,
where *A* represents the highest number possible for a batch, meaning
one single insertion. The other five levels consist in dividing the
previous one in half. The *A* value for each input size was previously
calculated and the rest was generated by the dividing the first
one. In this design, we have a six-levels factor, a three-levels
factor and $30$ replications, which results in $540$ experiments to
run in each of the four experimental units.

To complement this analysis, we also implemented a trace for the batch
executions. Every time there was an insertion in the database, we
collected the *start time* and *end time* of that specific batch. This
data is useful to obtain richer information about the impacts of the
batch mechanism in the performance. Next section demonstrates the
results for the experiments described above.


** Results and Graphics

We used the R language to merge the data from the different files
generated and to plot significant graphics of the results. The
hipotesis made before the execution of the experiments and the
observed results are presented below.

*** Comparison between Aiyra and PajeNG

For the experiment of comparison between Aiyra and PajeNG, we used the
average execution time among the $30$ replications as a
mesurement. The time is measured in seconds. We considered the
standard error to be three standard deviations of the mean, which
cover 99.7% of the cases in a normal distribution
\cite{normaldistribution}.

/Expected/ It is universally known that C++ is a language with better
performance than Java. We suppose that Aiyra will be slower than
PajeNG, but with an acceptable execution time. It is also expected
that the version *pj_flex* will be slower than *pj*, since *flex* has
the characteristic of having lower performance.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of comparison between Aiyra and PajeNG}
\centering
\includegraphics[width=\linewidth]{./img/cpp/aiyra-pj-pjflex_overview.pdf}
\label{fig.cppoverview}
\end{figure}
#+END_LaTeX

/Observed/ We can see in Figure \ref{fig.cppoverview} that, for the
*medium* and *big* inputs, Aiyra was actually faster than both
versions of PajeNG. To understand this results it is crucial to
recognize the difference between the implementation and configuration
of both programs. Aiyra is designed to get rid of the entities as soon
as they are finished. Thus, with the *PajeNullPlugin*, very little is
kept in memory. One of Java's biggest overhead is the memory handling,
specially the Garbage Collector(GC). Since we have an implementation
that stores as few objects as possible, and the less alive objects in
the program, the faster is GC \cite{garbagecollector}, Java may have a
chance in this case. Another important difference among Aiyra and
PajeNG is the process of reading the trace file, parsing it and then
sending to the simulator. As seen in Chapter \ref{chapter.paje}, the
PajeNG file reader first reads from the file a chunk of data, then the
decoder, which has predominant execution time, breaks it into events
and sends them to the simulator. The next segment of data is only read
after the first is completely decoded. On the other hand, Aiyra's
controller sends each event read immediately to the simulator. The
controller package performs the reading and parsing simultaneously and
is probably faster than the decoding process of PajeNG. Since the
memory allocation is not usually a problem in C++ implementations, it
is more likely that this result relies on the architectural
difference. As expected, the *pj_flex* version was slower than *pj*,
thus, slower than *aiyra*.

Notice that the experiment in *luiza* had a bigger variability with
the *pj* version and the *big* input. The average execution time for
the big file in the *aiyra* version was around $80$ seconds, but there
was an outlier experiment that executed in $2888$ seconds. This
particular row was removed from the data set. Even with this
particular case deleted, an instability can still be perceived. The
experiments are randomized in the design so, if there was any
disturbance in the environment during the experiment, it should have
affected other configurations as well, but we can notice the
variability only in this particular configuration. There is no
confirmed explanation for this situation, it may be because *luiza* is
the weakest machine in the experiment and did not handle well the C++
parsing with the biggest file. Considering that it does not affect the
overall analysis, the experiment was considered valid.

So far, we have analysed the execution time of the *medium* and *big*
inputs. In Figure \ref{fig.cppoverview}, we do not have a clear view
of the difference between the results of the *small* input in the
different platforms. Figure \ref{fig.cppsmall} portrays a closer sight
of the graphic, where we can see that the bahavior for the *small*
input is different from the others. In this case, we observe the
expected result. This is probably because it is a very small file,
with very few entities, so there is no memory overhead in either
versions and C++ is naturally faster than Java.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of comparison between Aiyra and PajeNG for the small input}
\centering
\includegraphics[width=\linewidth]{./img/cpp/aiyra-pj-pjflex_small.pdf}
\label{fig.cppsmall}
\end{figure}
#+END_LaTeX

These results are particularly important to assure the relevance of
this proposal. By deattaching the core simulation from the data
handling, we perceive that there is room for performance improvements
in the replay of large Pajé trace files. It is possible to observe
that the fewer we retain in memory, the better our performance will
be. The implementation of Aiyra gives the user more flexibility to
manage the memory usage of his program and space to develop high
performance implementations. It is also possible to notice that
changes in the architectural approach may have significan impacts in
the performance of the program.

*** PajeInsertDBPlugin evaluation

The objective of this experiment is to measure what is the best
balance between number of database accesses and memory usage. We have
already discarded inserting each entity at a time, so it is necessary
to keep entities temporarily in memory. We tested the simulation time
and memory usage for different combinations of input and batch size.
The response variables were: *execution time*, which is the total
duration of the execution; *insertion time*, the time it took to
insert the data in the database; and *maximum memory*, the maximum
usage of the memory during the simulation. For the execution and
simulation time, we used the average value as in the experiment
above. The memory value used was the maximum observed in the
replications. As this experiment consists in storing data of $540$
executions in memory, we used a =-test= flag, which drops the database
and recreates it after each simulation.

Since we had a very large number of experiments, it took
approximatedly $48$ hours to execute the design in each platform. In
the preliminary tests, we noticed that *orion1* was taking too long to
execute. This may have happened for several reasons, specially because
it is a machine shared by the students in the _*INF
UFRGS(??)*_. Although we locked the machine for the experiment, it was
out of our hands to stop eventual programs that could be running in
other students' users and affecting the performance. Likewise, it was
not desirable to unable other users from using the machine for longer
than two or three days. For these reasons, the experiment in *orion1*
had $10$ replications. The observation of little variability among the
executions in the exploratory tests support our decision.

/Expected/ According to the observation of bad performance when
executing excessive accesses to the database, we expect that the
bigger the batch, the better the performance, since it will make fewer
requests to MySQL. Naturally, this would also cause a higher memory
usage, so the maximum memory utilization will be larger for bigger
batches. We have three experiments making an access to a local
database, and one performing a remote connection. It is logical to
expect that the remote connection will take longer than the local
ones.  (improve)

/Observed/ As the values for A, B, C, D, E and F vary among the
different input sizes, it is consistent to analyze each input
separatedly. Figure \ref{fig.batchbig} illustrates the behavior of the
execution using the big input. We do not have results for batch size A
because we used the default values for the JVM, and it did not have
enough heap space to store the data. The *guarani* platform also did
not handle the B size. Although having less results, it is still
possible to observe a pattern which is the opposite as we imagined. We
can see that the smaller the batch size, the better the
performance. This is easily explained by the fact that Java's memory
management may be very slow, specially when there are many alive
objects in the program. By these results, we see that the memory usage
overhead is higher than the connection cost. With the medium input,
presented in Figure \ref{fig.batchmedium}, we observe the same
behavior as the big one for *luiza* and *guarani* platforms. *orion1*
results are inconclusive, probably due to the same problems mentioned
previously.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for big input}
\centering
\includegraphics[width=\linewidth]{./img/batch_size/local_big_v2.pdf}
\label{fig.batchbig}
\end{figure}
#+END_LaTeX

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for medium input}
\centering
\includegraphics[width=\linewidth]{./img/batch_size/local_medium_v1.pdf}
\label{fig.batchmedium}
\end{figure}
#+END_LaTeX

Going further on the analysis, we see in Figures \ref{fig.membig} and
\ref{fig.memmedium} the memory usage for the scenarios presented
above. Naturally, the memory usage peak is higher for bigger batches.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the big input}
\centering
\includegraphics[width=\linewidth]{./img/batch_size/local_mem_big_v1.pdf}
\label{fig.membig}
\end{figure}
#+END_LaTeX

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the mediuminput}
\centering
\includegraphics[width=\linewidth]{./img/batch_size/local_mem_medium_v1.pdf}
\label{fig.memmedium}
\end{figure}
#+END_LaTeX

For smaller inputs, however, we see (in Figure \ref{fig.batchsmall})
that the behavior is what we predicted. It is also explained by the
very little memory usage, that is too irrelevant to impact the
performance. It is worth mentioning that 128 Kilobytes, which is the
size of the *small* input, is very uncommon and that the usual traces
are at least in the Megabytes order of magnitude.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the small input}
\centering
\includegraphics[width=\linewidth]{./img/batch_size/local_small_v1.pdf}
\label{fig.batchsmall}
\end{figure}
#+END_LaTeX

(analysis on the remote, slower indeed?)

By analysing the results, we observed that the number of accesses to
the database did not impact on the performance of *big* and *medium*
traces. To support our conclusions, we generated traces for the batch
executions. These traces logged the duration of every batch insertion
for each experiment. It is depicted, in Figures \ref{fig.batchtimebig}
and \ref{fig.batchtimemedium}, $10$ replications of the executions,
for each batch size, represented in a timeline. It is possible to see
through these graphics that bigger batches take longer to execute, a
detail that we had not considered in the hipotesis. In this way, we
see that the insertion time does not significantly change between
configurations for the same input size, as the number of queries is
always the same, while the simulation itself is what impacts the run
time. As we have seen before, the memory usage is what penalizes the
performance.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the small input}
\centering
\includegraphics[width=\linewidth]{./img/batch_time/batch_time_big_v1.pdf}
\label{fig.batchtimebig}
\end{figure}
#+END_LaTeX

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the small input}
\centering
\includegraphics[width=\linewidth]{./img/batch_time/batch_time_medium_v1.pdf}
\label{fig.batchtimemedium}
\end{figure}
#+END_LaTeX

For the small input, we can observe, in Figure
\ref{fig.batchtimesmall}, the opposite behavior.

#+BEGIN_LaTeX
\begin{figure}[!htb]
\caption{Results of batch sizes variability for the small input}
\centering
\includegraphics[width=\linewidth]{./img/batch_time/batch_time_small_v1.pdf}
\label{fig.batchtimesmall}
\end{figure}
#+END_LaTeX


* 2016-05-16 CPP Comparison (figures)                   :noexport:Lucas:Tais:

Merge everything in a single CSV file:

#+begin_src sh :results output :session :exports both
cd results/cpp_comparison
head -n1 cpp_guarani_bateria01.csv > all_but_first.csv
for i in `ls -1 *.csv | grep -v _cpp_c`; do
  tail -n+2 $i
done >> all_but_first.csv
#+end_src

#+RESULTS:

Now, let's read the file =all_but_first.csv=.

#+begin_src R :results output :session :exports both
df <- read.csv ("results/cpp_comparison/all_but_first.csv");
df[df$version == "aiyra",]$time = df[df$version == "aiyra",]$time/1000000;
summary(df);
head(df);
#+end_src

#+RESULTS:
#+begin_example
      name       run.no.in.std.order     run.no      run.no.std.rp  
 Min.   :  1.0   Min.   :1           Min.   :  1.0   Min.   :1.100  
 1st Qu.: 68.0   1st Qu.:3           1st Qu.: 68.0   1st Qu.:3.160  
 Median :135.5   Median :5           Median :135.5   Median :5.225  
 Mean   :135.5   Mean   :5           Mean   :135.5   Mean   :5.290  
 3rd Qu.:203.0   3rd Qu.:7           3rd Qu.:203.0   3rd Qu.:7.300  
 Max.   :270.0   Max.   :9           Max.   :270.0   Max.   :9.900  
   version       input          time              platform  
 aiyra :270   big   :270   Min.   :   0.0245   guarani:270  
 pj    :270   medium:270   1st Qu.:   0.1738   luiza  :270  
 pjflex:270   small :270   Median :  25.7898   orion1 :270  
                           Mean   :  76.8609                
                           3rd Qu.: 123.2365                
                           Max.   :2888.0565
  name run.no.in.std.order run.no run.no.std.rp version  input       time
1    1                   4      1           4.1   aiyra medium  13.199061
2    2                   9      2           9.1  pjflex    big 280.152443
3    3                   2      3           2.1      pj  small   0.049384
4    4                   5      4           5.1      pj medium  33.616784
5    5                   7      5           7.1   aiyra    big 111.191072
6    6                   6      6           6.1  pjflex medium  35.570650
  platform
1   orion1
2   orion1
3   orion1
4   orion1
5   orion1
6   orion1
#+end_example

Let's average measurements:

#+begin_src R :results output :session :exports both
library(dplyr);
k <- df %>%
     select(version, input, time, platform) %>%
     group_by(version, input, platform) %>%
     summarize(N = n(),
               time_avg = mean(time),
               time_se = 3*sd(time)/sqrt(N)) %>%
     as.data.frame();
k
#+end_src

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
   version  input platform  N     time_avg      time_se
1    aiyra    big  guarani 30 124.24501307 1.152943e+00
2    aiyra    big    luiza 30 176.45010810 2.805133e+02
3    aiyra    big   orion1 30 111.78373253 1.012192e+00
4    aiyra medium  guarani 30  13.62979877 2.309004e-01
5    aiyra medium    luiza 30   9.38572857 1.159134e-01
6    aiyra medium   orion1 30  13.08560363 1.239769e-01
7    aiyra  small  guarani 30   0.17240930 1.343752e-03
8    aiyra  small    luiza 30   0.18415197 1.450459e-03
9    aiyra  small   orion1 30   0.22622977 9.292423e-03
10      pj    big  guarani 30 232.04630737 5.956094e-01
11      pj    big    luiza 30 207.43421557 9.992199e+00
12      pj    big   orion1 30 259.72360747 1.115893e+00
13      pj medium  guarani 30  29.97373843 1.207393e-01
14      pj medium    luiza 30  24.92862427 2.842269e-01
15      pj medium   orion1 30  33.47163073 1.253937e-01
16      pj  small  guarani 30   0.04223553 6.087253e-03
17      pj  small    luiza 30   0.02562413 7.886749e-04
18      pj  small   orion1 30   0.04607153 2.206699e-03
19  pjflex    big  guarani 30 248.65192840 1.108033e+00
20  pjflex    big    luiza 30 215.79006593 2.822790e+00
21  pjflex    big   orion1 30 279.74462510 9.249580e-01
22  pjflex medium  guarani 30  32.14986230 1.422113e-01
23  pjflex medium    luiza 30  25.85007707 2.419624e-01
24  pjflex medium   orion1 30  36.08434247 1.588962e-01
25  pjflex  small  guarani 30   0.04453450 5.719485e-03
26  pjflex  small    luiza 30   0.02540013 4.037376e-04
27  pjflex  small   orion1 30   0.04819160 2.599552e-03
#+end_example

#+begin_src R :results output graphics :file img/cpp/first_plot_1.png :exports both :width 600 :height 400 :session
library(ggplot2);
ggplot(k, aes(x=version, y=time_avg, color=input)) +
  geom_point() +
  scale_colour_manual(values = c("red","blue", "green")) +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  theme_bw() + facet_wrap(~platform);
#+end_src

#+RESULTS:
[[file:img/cpp/first_plot_1.png]]

There is something really strange with =luiza= =aiyra= =big=, let's look to
the measurements.

#+begin_src R :results output :session :exports both
df[df$platform == "luiza" & df$version == "aiyra" & df$input == "big",];
#+end_src

#+RESULTS:
#+begin_example
    name run.no.in.std.order run.no run.no.std.rp version input       time
275    5                   7      5          7.10   aiyra   big   82.81775
281   11                   7     11          7.20   aiyra   big   86.17196
296   26                   7     26          7.30   aiyra   big 2888.05648
299   29                   7     29          7.40   aiyra   big   80.86330
314   44                   7     44          7.50   aiyra   big   82.80871
321   51                   7     51          7.60   aiyra   big   80.60814
325   55                   7     55          7.70   aiyra   big   81.70027
335   65                   7     65          7.80   aiyra   big   81.60717
346   76                   7     76          7.90   aiyra   big   81.75732
359   89                   7     89          7.10   aiyra   big   81.35299
364   94                   7     94          7.11   aiyra   big   83.07451
372  102                   7    102          7.12   aiyra   big   86.38635
382  112                   7    112          7.13   aiyra   big   84.73248
394  124                   7    124          7.14   aiyra   big   84.30511
403  133                   7    133          7.15   aiyra   big   83.61456
406  136                   7    136          7.16   aiyra   big   87.41428
422  152                   7    152          7.17   aiyra   big   82.55839
430  160                   7    160          7.18   aiyra   big   83.14233
433  163                   7    163          7.19   aiyra   big   82.74059
443  173                   7    173          7.20   aiyra   big   80.96755
455  185                   7    185          7.21   aiyra   big   83.47831
461  191                   7    191          7.22   aiyra   big   82.58781
474  204                   7    204          7.23   aiyra   big   80.05653
483  213                   7    213          7.24   aiyra   big   80.95360
487  217                   7    217          7.25   aiyra   big   84.05692
500  230                   7    230          7.26   aiyra   big   84.04072
509  239                   7    239          7.27   aiyra   big   88.34312
518  248                   7    248          7.28   aiyra   big   81.86359
525  255                   7    255          7.29   aiyra   big   80.94467
533  263                   7    263          7.30   aiyra   big   80.49776
    platform
275    luiza
281    luiza
296    luiza
299    luiza
314    luiza
321    luiza
325    luiza
335    luiza
346    luiza
359    luiza
364    luiza
372    luiza
382    luiza
394    luiza
403    luiza
406    luiza
422    luiza
430    luiza
433    luiza
443    luiza
455    luiza
461    luiza
474    luiza
483    luiza
487    luiza
500    luiza
509    luiza
518    luiza
525    luiza
533    luiza
#+end_example

We need to remove the outlier where execution time took $2888.05648$
seconds. To do so, we modify the =df= dataframe:

#+begin_src R :results output :session :exports both
df2 <- df[df$time < 2000,]
df2[df2$platform == "luiza" & df2$version == "aiyra" & df2$input == "big",];

#+end_src

#+RESULTS:
#+begin_example
    name run.no.in.std.order run.no run.no.std.rp version input     time
275    5                   7      5          7.10   aiyra   big 82.81775
281   11                   7     11          7.20   aiyra   big 86.17196
299   29                   7     29          7.40   aiyra   big 80.86330
314   44                   7     44          7.50   aiyra   big 82.80871
321   51                   7     51          7.60   aiyra   big 80.60814
325   55                   7     55          7.70   aiyra   big 81.70027
335   65                   7     65          7.80   aiyra   big 81.60717
346   76                   7     76          7.90   aiyra   big 81.75732
359   89                   7     89          7.10   aiyra   big 81.35299
364   94                   7     94          7.11   aiyra   big 83.07451
372  102                   7    102          7.12   aiyra   big 86.38635
382  112                   7    112          7.13   aiyra   big 84.73248
394  124                   7    124          7.14   aiyra   big 84.30511
403  133                   7    133          7.15   aiyra   big 83.61456
406  136                   7    136          7.16   aiyra   big 87.41428
422  152                   7    152          7.17   aiyra   big 82.55839
430  160                   7    160          7.18   aiyra   big 83.14233
433  163                   7    163          7.19   aiyra   big 82.74059
443  173                   7    173          7.20   aiyra   big 80.96755
455  185                   7    185          7.21   aiyra   big 83.47831
461  191                   7    191          7.22   aiyra   big 82.58781
474  204                   7    204          7.23   aiyra   big 80.05653
483  213                   7    213          7.24   aiyra   big 80.95360
487  217                   7    217          7.25   aiyra   big 84.05692
500  230                   7    230          7.26   aiyra   big 84.04072
509  239                   7    239          7.27   aiyra   big 88.34312
518  248                   7    248          7.28   aiyra   big 81.86359
525  255                   7    255          7.29   aiyra   big 80.94467
533  263                   7    263          7.30   aiyra   big 80.49776
    platform
275    luiza
281    luiza
299    luiza
314    luiza
321    luiza
325    luiza
335    luiza
346    luiza
359    luiza
364    luiza
372    luiza
382    luiza
394    luiza
403    luiza
406    luiza
422    luiza
430    luiza
433    luiza
443    luiza
455    luiza
461    luiza
474    luiza
483    luiza
487    luiza
500    luiza
509    luiza
518    luiza
525    luiza
533    luiza
#+end_example

Great, it has worked.

Recalculate the averages, do the plot again.

#+begin_src R :results output :session :exports both
library(dplyr);
k2 <- df2 %>%
     select(version, input, time, platform) %>%
     group_by(version, input, platform) %>%
     summarize(N = n(),
               time_avg = mean(time),
               time_se = 3*sd(time)/sqrt(N)) %>%
     as.data.frame();
k2
#+end_src

#+RESULTS:
#+begin_example
   version  input platform  N     time_avg      time_se
1    aiyra    big  guarani 30 124.24501307 1.1529429416
2    aiyra    big    luiza 29  82.94644007 1.1744753970
3    aiyra    big   orion1 30 111.78373253 1.0121923958
4    aiyra medium  guarani 30  13.62979877 0.2309003501
5    aiyra medium    luiza 30   9.38572857 0.1159133555
6    aiyra medium   orion1 30  13.08560363 0.1239768599
7    aiyra  small  guarani 30   0.17240930 0.0013437523
8    aiyra  small    luiza 30   0.18415197 0.0014504593
9    aiyra  small   orion1 30   0.22622977 0.0092924233
10      pj    big  guarani 30 232.04630737 0.5956093796
11      pj    big    luiza 30 207.43421557 9.9921988357
12      pj    big   orion1 30 259.72360747 1.1158926857
13      pj medium  guarani 30  29.97373843 0.1207393162
14      pj medium    luiza 30  24.92862427 0.2842269263
15      pj medium   orion1 30  33.47163073 0.1253936889
16      pj  small  guarani 30   0.04223553 0.0060872534
17      pj  small    luiza 30   0.02562413 0.0007886749
18      pj  small   orion1 30   0.04607153 0.0022066994
19  pjflex    big  guarani 30 248.65192840 1.1080330952
20  pjflex    big    luiza 30 215.79006593 2.8227903219
21  pjflex    big   orion1 30 279.74462510 0.9249579906
22  pjflex medium  guarani 30  32.14986230 0.1422112908
23  pjflex medium    luiza 30  25.85007707 0.2419624421
24  pjflex medium   orion1 30  36.08434247 0.1588962252
25  pjflex  small  guarani 30   0.04453450 0.0057194849
26  pjflex  small    luiza 30   0.02540013 0.0004037376
27  pjflex  small   orion1 30   0.04819160 0.0025995518
#+end_example

#+begin_src R :results output graphics :file img/cpp/aiyra-pj-pjflex_overview.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2, aes(x=version, y=time_avg, color=input)) +
  geom_point() +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  scale_colour_manual(values = c("red","blue", "green"), name="Input Size") +
  theme_bw() + facet_wrap(~platform) +
  ylab("Average Execution Time (s)") +
  xlab("Version") +
  ggtitle ("Comparing Aiyra against two versions of PajeNG") +
  theme_bw() + ylim(0,NA) + 
  theme(legend.position="right"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/cpp/aiyra-pj-pjflex_overview.pdf]]

You have to explain the larger variability during the =luiza=, =pj=,
=big=. Maybe because something was disturbing the experiment during that
time. But remember we have randomize the design, so, it should have
affected other configurations as well.

#+begin_src R :results output :session :exports both
df[df$platform == "luiza" & df$version == "pj" & df$input == "big",];

#+end_src

#+RESULTS:
#+begin_example
    name run.no.in.std.order run.no run.no.std.rp version input     time
279    9                   8      9          8.10      pj   big 203.8820
282   12                   8     12          8.20      pj   big 303.2675
297   27                   8     27          8.30      pj   big 208.4385
301   31                   8     31          8.40      pj   big 202.1743
311   41                   8     41          8.50      pj   big 203.3942
322   52                   8     52          8.60      pj   big 204.3809
330   60                   8     60          8.70      pj   big 205.7884
334   64                   8     64          8.80      pj   big 202.2098
351   81                   8     81          8.90      pj   big 205.4249
354   84                   8     84          8.10      pj   big 203.5652
367   97                   8     97          8.11      pj   big 206.1473
377  107                   8    107          8.12      pj   big 203.0834
384  114                   8    114          8.13      pj   big 205.3515
393  123                   8    123          8.14      pj   big 204.3712
401  131                   8    131          8.15      pj   big 203.8469
408  138                   8    138          8.16      pj   big 203.6601
419  149                   8    149          8.17      pj   big 204.7679
425  155                   8    155          8.18      pj   big 200.8791
440  170                   8    170          8.19      pj   big 199.3703
449  179                   8    179          8.20      pj   big 204.9851
454  184                   8    184          8.21      pj   big 206.1524
466  196                   8    196          8.22      pj   big 202.3681
472  202                   8    202          8.23      pj   big 206.3542
479  209                   8    209          8.24      pj   big 204.6642
491  221                   8    221          8.25      pj   big 205.7807
503  233                   8    233          8.26      pj   big 209.4978
505  235                   8    235          8.27      pj   big 198.3630
515  245                   8    245          8.28      pj   big 203.5347
530  260                   8    260          8.29      pj   big 203.6857
539  269                   8    269          8.30      pj   big 203.6370
    platform
279    luiza
282    luiza
297    luiza
301    luiza
311    luiza
322    luiza
330    luiza
334    luiza
351    luiza
354    luiza
367    luiza
377    luiza
384    luiza
393    luiza
401    luiza
408    luiza
419    luiza
425    luiza
440    luiza
449    luiza
454    luiza
466    luiza
472    luiza
479    luiza
491    luiza
503    luiza
505    luiza
515    luiza
530    luiza
539    luiza
#+end_example

You can see a =300= seconds measurement that probably is the explanation
for the higher standard error. We don't know, we could remove it, but
you can keep it and explain with something. Maybe mention that is
unrelated, because the experimental execution order was 12 for this
one..., with the other outlier you have seen also in =luiza= (see
above).

Ok.

Aiyra wins for big and medium. What about small? We can't see, let's
do a plot only about it.


#+begin_src R :results output graphics :file img/cpp/first_plot_3.png :exports both :width 600 :height 400 :session
library(ggplot2);
ggplot(k2[k2$input == "small",], aes(x=version, y=time_avg, color=input)) +
  geom_point() +
  scale_colour_manual(values = c("green")) +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  theme_bw() + facet_wrap(~platform);
#+end_src

#+RESULTS:
[[file:img/cpp/first_plot_3.png]]

Aiyra loses. But pay the attention to the colors now (also .

Let's do this same plot in PDF so you can include in your
dissertation.

#+begin_src R :results output graphics :file img/cpp/aiyra-pj-pjflex_small.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "small",], aes(x=version, y=time_avg, color=input)) +
  geom_point() +
  scale_colour_manual(values = c("green"), name="Input") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Version") +
  ggtitle ("Comparing Aiyra against two versions\n of PajeNG for a small input") +
  theme_bw() + ylim(0,NA) + 
  facet_wrap(~platform) +
#  title ("teste") +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/cpp/aiyra-pj-pjflex_small.pdf]]


* 2016-05-17 Batch size (figures)                       :noexport:Lucas:Tais:

For local analysis:

#+begin_src sh :results output :session :exports both
  head -n1 results/batch_size/bateria03_orion1_batch.csv > results/batch_size/local.csv
  for file in "results/batch_size/bateria03_orion1_batch.csv results/batch_size/last_guarani_batch.csv results/batch_size/ultimabat_luiza_batch.csv"; do
      tail -n+2 $file
  done >> results/batch_size/local.csv
#+end_src

#+RESULTS:

For remote against local analysis:

#+begin_src sh :results output :session :exports both
  head -n1 results/batch_size/bateria03_orion1_batch.csv > results/batch_size/remote.csv
  for file in "results/batch_size/bateria03_orion1_batch.csv results/batch_size/last_guarani_batch.csv results/batch_size/ultimabat_luiza_batch.csv results/batch_size/bateria01_batch_guarani_orion.csv"; do
      tail -n+2 $file
  done >> results/batch_size/remote.csv
#+end_src

#+RESULTS:

_Local_

Now, let's read the file =local.csv=.

#+begin_src R :results output :session :exports both
df <- read.csv ("results/batch_size/local.csv");
df <- df[complete.cases(df),];
df$sim_time <- as.numeric(as.character(df$sim_time));
df$insert_time <- as.numeric(as.character(df$insert_time));
df$sim_time = df$sim_time/1000000;
df$insert_time = df$insert_time/1000000;
df$max_mem = df$max_mem/1024/1024;
head(df);
#+end_src

#+RESULTS:
#+begin_example
  name run.no.in.std.order run.no run.no.std.rp  input batch   sim_time
2    1                   7      1           7.1  small     D   0.983336
3    2                  15      2          15.1    big     F 950.015134
4    3                   4      3           4.1  small     C   0.872588
5    4                  10      4          10.1  small     E   1.231774
6    5                  13      5          13.1  small     F   1.633785
7    6                  11      6          11.1 medium     E  93.070116
  insert_time    max_mem platform
2    0.202030   3.073425   orion1
3  401.292651 257.339241   orion1
4    0.227659   3.226997   orion1
5    0.256816   3.005371   orion1
6    0.285011   2.969864   orion1
7   52.138141  67.714127   orion1
#+end_example

Let's average measurements:

#+begin_src R :results output :session :exports both
library(dplyr);
k <- df %>%
     group_by(input, batch, platform) %>%
     summarize(N = n(),
               time_avg = mean(sim_time),
               time_se = 3*sd(sim_time)/sqrt(N)) %>%
     as.data.frame();
k
#+end_src

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
    input batch platform  N     time_avg      time_se
1     big     B   orion1 10 1107.3227606 6.658932e+00
2     big     C  guarani 30  824.7546429 2.852808e+00
3     big     C    luiza 30  772.6744859 2.081221e+00
4     big     C   orion1 10 1061.8112710 5.241099e+00
5     big     D  guarani 30  798.8587828 2.957737e+00
6     big     D    luiza 30  796.5267459 1.858931e+02
7     big     D   orion1 10 1026.6392053 5.417082e+00
8     big     E  guarani 30  780.5554274 2.658481e+00
9     big     E    luiza 30  718.6369158 1.532428e+00
10    big     E   orion1 10  997.8075534 5.549207e+00
11    big     F  guarani 30  771.4025417 2.914140e+00
12    big     F    luiza 30  711.4194856 1.529460e+00
13    big     F   orion1 10  946.2533760 3.886924e+00
14 medium     A  guarani 30  100.3892080 4.840424e-01
15 medium     A    luiza 30   93.9088443 1.835017e-01
16 medium     B  guarani 30   99.2527799 4.786725e-01
17 medium     B    luiza 30   93.1713426 1.855400e-01
18 medium     B   orion1 10  106.2926635 3.040111e+00
19 medium     C  guarani 30   95.0724998 5.849231e-01
20 medium     C    luiza 30   88.3279745 2.877727e-01
21 medium     C   orion1 10  111.3229354 9.112576e-01
22 medium     D  guarani 30   96.9286011 5.696124e-01
23 medium     D    luiza 30   87.5662485 2.059891e-01
24 medium     D   orion1 10  117.2014197 8.836928e-01
25 medium     E  guarani 30   92.5820661 5.123305e-01
26 medium     E    luiza 30   86.1899532 1.962095e-01
27 medium     E   orion1 10   97.4553447 7.025395e+00
28 medium     F  guarani 30   92.4204530 4.873207e-01
29 medium     F    luiza 30   82.4328944 2.428668e-01
30 medium     F   orion1 10  109.6810972 9.403754e-01
31  small     A  guarani 30    0.4956575 6.162893e-03
32  small     A    luiza 30    0.4502067 3.531458e-03
33  small     B  guarani 30    0.5281257 9.840373e-03
34  small     B    luiza 30    0.4528172 2.666560e-03
35  small     B   orion1 10    0.7557264 2.225693e-02
36  small     C  guarani 30    0.5544556 1.253729e-02
37  small     C    luiza 30    0.4709659 2.894954e-03
38  small     C   orion1 10    0.8611910 2.868396e-02
39  small     D  guarani 30    0.5818487 1.325817e-02
40  small     D    luiza 30    0.5158810 3.757003e-03
41  small     D   orion1 10    0.9929203 2.956740e-02
42  small     E  guarani 30    0.6681839 1.538822e-02
43  small     E    luiza 30    0.6011176 3.310887e-03
44  small     E   orion1 10    1.2279947 2.983281e-02
45  small     F  guarani 30    0.8698209 9.727556e-03
46  small     F    luiza 30    0.7695288 8.467496e-03
47  small     F   orion1 10    1.6951738 3.660555e-02
#+end_example


#+begin_src R :results output graphics :file img/batch_size/local_big_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k[k$input == "big",], aes(x=batch, y=time_avg)) +
  geom_point(size=.3) +
#  scale_colour_manual(values = c("green"), name="Input") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(input~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_v1.pdf]]

Very strange behavior on =luiza=, batch =D= because of the high
variability. Let's see the data:

#+begin_src R :results output :session :exports both
df[df$input == "big" & df$platform == "luiza" & df$batch == "D",];
#+end_src

#+RESULTS:
#+begin_example
     name run.no.in.std.order run.no run.no.std.rp input batch  sim_time
697     4                  12      4         12.10   big     D  734.4769
720    27                  12     27         12.20   big     D  731.5318
736    43                  12     43         12.30   big     D  732.5503
751    58                  12     58         12.40   big     D  739.5146
780    87                  12     87         12.50   big     D  727.4080
784    91                  12     91         12.60   big     D  733.0804
813   120                  12    120         12.70   big     D  737.1977
829   136                  12    136         12.80   big     D  732.3844
843   150                  12    150         12.90   big     D  734.6302
864   171                  12    171         12.10   big     D  730.9828
884   191                  12    191         12.11   big     D  736.7343
901   208                  12    208         12.12   big     D  732.6899
922   229                  12    229         12.13   big     D  732.8134
931   238                  12    238         12.14   big     D  734.9025
956   263                  12    263         12.15   big     D  739.9419
974   281                  12    281         12.16   big     D  738.1100
982   289                  12    289         12.17   big     D  732.5317
1017  324                  12    324         12.18   big     D  737.1109
1026  333                  12    333         12.19   big     D 2593.4167
1044  351                  12    351         12.20   big     D  736.5624
1054  361                  12    361         12.21   big     D  734.8892
1076  383                  12    383         12.22   big     D  727.3046
1095  402                  12    402         12.23   big     D  734.8349
1123  430                  12    430         12.24   big     D  733.0345
1141  448                  12    448         12.25   big     D  740.3488
1157  464                  12    464         12.26   big     D  735.1516
1175  482                  12    482         12.27   big     D  736.5852
1187  494                  12    494         12.28   big     D  734.3452
1200  507                  12    507         12.29   big     D  737.0423
1224  531                  12    531         12.30   big     D  733.6951
     insert_time  max_mem platform
697     423.1795 1020.664    luiza
720     419.9057 1020.664    luiza
736     419.1899 1020.664    luiza
751     422.4795 1020.666    luiza
780     415.7618 1020.663    luiza
784     420.4074 1020.666    luiza
813     422.9430 1020.663    luiza
829     419.7894 1020.663    luiza
843     420.1070 1020.665    luiza
864     419.8785 1020.667    luiza
884     422.2966 1020.664    luiza
901     421.6495 1020.664    luiza
922     421.8006 1020.664    luiza
931     420.3353 1020.663    luiza
956     426.4439 1020.665    luiza
974     419.1994 1020.664    luiza
982     421.6567 1020.663    luiza
1017    420.3747 1020.664    luiza
1026   2279.5546 1020.664    luiza
1044    423.0635 1020.663    luiza
1054    421.1642 1020.667    luiza
1076    417.9471 1020.664    luiza
1095    424.2948 1020.663    luiza
1123    416.0131 1020.664    luiza
1141    421.1605 1020.663    luiza
1157    422.0469 1020.663    luiza
1175    419.2871 1020.663    luiza
1187    421.2706 1020.664    luiza
1200    420.1514 1020.663    luiza
1224    421.4753 1020.664    luiza
#+end_example

Looks like there was a problem when inserting in the database. We'll
manually remove this outlier. You should mention this on the text.

#+begin_src R :results output :session :exports both
dff <- df[df$name != 333,];
k2 <- dff %>%
     group_by(input, batch, platform) %>%
     summarize(N = n(),
               time_avg = mean(sim_time),
               time_se = 3*sd(sim_time)/sqrt(N)) %>%
     as.data.frame();
k2
#+end_src

#+RESULTS:
#+begin_example
    input batch platform  N     time_avg     time_se
1     big     B   orion1 10 1107.3227606 6.658931757
2     big     C  guarani 30  824.7546429 2.852807810
3     big     C    luiza 30  772.6744859 2.081221420
4     big     C   orion1 10 1061.8112710 5.241098578
5     big     D  guarani 29  798.5691785 2.926487070
6     big     D    luiza 29  734.5650227 1.771873261
7     big     D   orion1 10 1026.6392053 5.417082452
8     big     E  guarani 30  780.5554274 2.658481151
9     big     E    luiza 30  718.6369158 1.532427809
10    big     E   orion1 10  997.8075534 5.549207079
11    big     F  guarani 30  771.4025417 2.914139674
12    big     F    luiza 30  711.4194856 1.529459777
13    big     F   orion1 10  946.2533760 3.886923906
14 medium     A  guarani 30  100.3892080 0.484042387
15 medium     A    luiza 30   93.9088443 0.183501686
16 medium     B  guarani 30   99.2527799 0.478672535
17 medium     B    luiza 30   93.1713426 0.185540020
18 medium     B   orion1 10  106.2926635 3.040111400
19 medium     C  guarani 30   95.0724998 0.584923080
20 medium     C    luiza 30   88.3279745 0.287772713
21 medium     C   orion1 10  111.3229354 0.911257568
22 medium     D  guarani 30   96.9286011 0.569612415
23 medium     D    luiza 30   87.5662485 0.205989135
24 medium     D   orion1 10  117.2014197 0.883692783
25 medium     E  guarani 30   92.5820661 0.512330528
26 medium     E    luiza 30   86.1899532 0.196209532
27 medium     E   orion1 10   97.4553447 7.025394616
28 medium     F  guarani 30   92.4204530 0.487320713
29 medium     F    luiza 30   82.4328944 0.242866845
30 medium     F   orion1 10  109.6810972 0.940375391
31  small     A  guarani 30    0.4956575 0.006162893
32  small     A    luiza 30    0.4502067 0.003531458
33  small     B  guarani 30    0.5281257 0.009840373
34  small     B    luiza 30    0.4528172 0.002666560
35  small     B   orion1 10    0.7557264 0.022256931
36  small     C  guarani 30    0.5544556 0.012537292
37  small     C    luiza 30    0.4709659 0.002894954
38  small     C   orion1 10    0.8611910 0.028683959
39  small     D  guarani 30    0.5818487 0.013258166
40  small     D    luiza 30    0.5158810 0.003757003
41  small     D   orion1 10    0.9929203 0.029567395
42  small     E  guarani 30    0.6681839 0.015388218
43  small     E    luiza 30    0.6011176 0.003310887
44  small     E   orion1 10    1.2279947 0.029832810
45  small     F  guarani 30    0.8698209 0.009727556
46  small     F    luiza 30    0.7695288 0.008467496
47  small     F   orion1 10    1.6951738 0.036605546
#+end_example

#+begin_src R :results output graphics :file img/batch_size/local_big_v2.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "big",], aes(x=batch, y=time_avg, color=input)) +
  geom_point(size=.3) +
  scale_colour_manual(values = c("red","blue", "green"), name="Input Size") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_wrap(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_big_v2.pdf]]

Much better now.

Let's look to the =medium= size.

#+begin_src R :results output graphics :file img/batch_size/local_medium_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "medium",], aes(x=batch, y=time_avg, color=input)) +
  geom_point(size=.3) +
  scale_colour_manual(values = c("blue"), name="Input") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_medium_v1.pdf]]

#+begin_src R :results output graphics :file img/batch_size/local_small_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "small",], aes(x=batch, y=time_avg, color=input)) +
  geom_point(size=.3) +
  scale_colour_manual(values = c("green"), name="Input") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_small_v1.pdf]]

It's different for small. Maybe it should be interesting to plot in
the graph the three inputs, so we can see the different trend for
small.

#+begin_src R :results output graphics :file img/batch_size/local_all_inputs_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2, aes(x=batch, y=time_avg, color=input)) +
  geom_point(size=.3) +
  scale_colour_manual(values = c("red", "blue", "green"), name="Input Size") +
  geom_errorbar(aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(input~platform, scales="free_y") +
  theme(legend.position="right"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_all_inputs_v1.pdf]]

Great, Tais will write in the text that she explains all three first
plots, then to show the different trend, she uses =local_all_inputs_v1=
plot.

Remember =pdfcrop=.

_Remote_

Now, let's read the file =remote.csv=.

#+begin_src R :results output :session :exports both
df <- read.csv ("results/batch_size/remote.csv");
df <- df[complete.cases(df),];
df$sim_time <- as.numeric(as.character(df$sim_time));
df$insert_time <- as.numeric(as.character(df$insert_time));
df$sim_time = df$sim_time/1000000;
df$insert_time = df$insert_time/1000000;
df$max_mem = df$max_mem/1024/1024;
head(df);

dft1 <- df[df$platform != "guarani_orion",];
dft2 <- df[df$platform == "guarani_orion",];
dft2$platform <- "remote";
df <- rbind(dft2, dft1);
head(df);
#+end_src

#+RESULTS:
#+begin_example
  name run.no.in.std.order run.no run.no.std.rp  input batch   sim_time
2    1                   7      1           7.1  small     D   0.983336
3    2                  15      2          15.1    big     F 950.015134
4    3                   4      3           4.1  small     C   0.872588
5    4                  10      4          10.1  small     E   1.231774
6    5                  13      5          13.1  small     F   1.633785
7    6                  11      6          11.1 medium     E  93.070116
  insert_time    max_mem platform
2    0.202030   3.073425   orion1
3  401.292651 257.339241   orion1
4    0.227659   3.226997   orion1
5    0.256816   3.005371   orion1
6    0.285011   2.969864   orion1
7   52.138141  67.714127   orion1
     name run.no.in.std.order run.no run.no.std.rp  input batch  sim_time
1235    1                   8      1           8.1 medium     C  95.72919
1236    2                  18      2          18.1    big     F 765.60935
1237    3                   5      3           5.1 medium     B  98.47585
1238    4                  12      4          12.1    big     D 792.44906
1239    5                  16      5          16.1  small     F   0.90444
1241    7                  15      7          15.1    big     E 775.00969
     insert_time     max_mem platform
1235    63.87650  264.647064   remote
1236   480.09590  257.338707   remote
1237    62.73813  527.779396   remote
1238   482.47624 1020.575333   remote
1239     0.20935    2.970314   remote
1241   482.44408  513.167862   remote
#+end_example

Let's average measurements:

#+begin_src R :results output :session :exports both
library(dplyr);
k <- df %>%
     group_by(input, batch, platform) %>%
     summarize(N = n(),
               time_avg = mean(sim_time),
               time_se = 3*sd(sim_time)/sqrt(N)) %>%
     as.data.frame();
k[k$platform =="remote",]
#+end_src

#+RESULTS:
#+begin_example
    input batch platform  N    time_avg     time_se
5     big     C   remote 30 822.9541185 3.072009855
9     big     D   remote 30 793.6288847 2.793609013
13    big     E   remote 30 776.9857812 3.234269351
17    big     F   remote 30 765.5748142 2.850922209
20 medium     A   remote 30 100.0850588 0.438621535
24 medium     B   remote 30  98.6565419 0.657277641
28 medium     C   remote 30  94.7818702 0.528655405
32 medium     D   remote 30  96.5232222 0.502179305
36 medium     E   remote 30  92.0910381 0.393890608
40 medium     F   remote 30  92.0036549 0.480806287
43  small     A   remote 30   0.4990605 0.007578415
47  small     B   remote 30   0.5296416 0.009928985
51  small     C   remote 30   0.5577120 0.010474202
55  small     D   remote 30   0.5934754 0.016890922
59  small     E   remote 30   0.6592223 0.014014033
63  small     F   remote 30   0.8761198 0.015386276
#+end_example

For =remote=, guarani had aiyra; orion1 had the database. Tais will
check the scripts to confirm and check since this is very important.

So, since =guarani= was involved, let's compare =remote= agains it because
it means we took out the database from guarani and put in another
machine (in this case =orion=). The objective of our analysis here is to
see the network impact in the execution comparing with a situation
where everything resides in the same machine.

Future work idea:
- create a producer/consumer version where insert requests are put in
  a queue; another thread will be responsible for insertion. We could
  implement another plugin that is threaded.

So, let's take only =guarani= and =remote= measurements.

#+begin_src R :results output :session :exports both
k2 <- k[k$platform == "guarani" | k$platform == "remote",];
k2
#+end_src

#+RESULTS:
#+begin_example
    input batch platform  N    time_avg     time_se
2     big     C  guarani 30 824.7546429 2.852807810
5     big     C   remote 30 822.9541185 3.072009855
6     big     D  guarani 30 798.8587828 2.957736903
9     big     D   remote 30 793.6288847 2.793609013
10    big     E  guarani 30 780.5554274 2.658481151
13    big     E   remote 30 776.9857812 3.234269351
14    big     F  guarani 30 771.4025417 2.914139674
17    big     F   remote 30 765.5748142 2.850922209
18 medium     A  guarani 30 100.3892080 0.484042387
20 medium     A   remote 30 100.0850588 0.438621535
21 medium     B  guarani 30  99.2527799 0.478672535
24 medium     B   remote 30  98.6565419 0.657277641
25 medium     C  guarani 30  95.0724998 0.584923080
28 medium     C   remote 30  94.7818702 0.528655405
29 medium     D  guarani 30  96.9286011 0.569612415
32 medium     D   remote 30  96.5232222 0.502179305
33 medium     E  guarani 30  92.5820661 0.512330528
36 medium     E   remote 30  92.0910381 0.393890608
37 medium     F  guarani 30  92.4204530 0.487320713
40 medium     F   remote 30  92.0036549 0.480806287
41  small     A  guarani 30   0.4956575 0.006162893
43  small     A   remote 30   0.4990605 0.007578415
44  small     B  guarani 30   0.5281257 0.009840373
47  small     B   remote 30   0.5296416 0.009928985
48  small     C  guarani 30   0.5544556 0.012537292
51  small     C   remote 30   0.5577120 0.010474202
52  small     D  guarani 30   0.5818487 0.013258166
55  small     D   remote 30   0.5934754 0.016890922
56  small     E  guarani 30   0.6681839 0.015388218
59  small     E   remote 30   0.6592223 0.014014033
60  small     F  guarani 30   0.8698209 0.009727556
63  small     F   remote 30   0.8761198 0.015386276
#+end_example


#+begin_src R :results output graphics :file img/batch_size/remote_big_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "big",], aes(x=batch, y=time_avg, color=platform)) +
  geom_point(position=position_dodge(width=0.3)) +
  scale_colour_manual(values = c("red", "blue", "green"), name="Platform") +
  geom_errorbar(position=position_dodge(width=0.3), aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="right"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/remote_big_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_size/remote_medium_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "medium",], aes(x=batch, y=time_avg, color=platform)) +
  geom_point(position=position_dodge(width=0.3)) +
  scale_colour_manual(values = c("red", "blue", "green"), name="Platform") +
  geom_errorbar(position=position_dodge(width=0.3), aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="right"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/remote_medium_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_size/remote_small_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k2[k2$input == "small",], aes(x=batch, y=time_avg, color=platform)) +
  geom_point(position=position_dodge(width=0.3)) +
  scale_colour_manual(values = c("red", "blue", "green"), name="Platform") +
  geom_errorbar(position=position_dodge(width=0.3), aes(ymin=time_avg-time_se, ymax=time_avg+time_se), width=.1) +
  ylab("Average Execution Time (s)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="right"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/remote_small_v1.pdf]]

Tais just found out that =guarani= is fact =remote=. She will do the
experiment again so we can correctly compare a local against a remove
experiment. All plots regarding batch size will have to be re-plotted.

#+begin_src R :results output :session :exports both
k2[k2$platform == "guarani",];
sum(10 * k2$time_avg)/60/60/24;
#+end_src

#+RESULTS:
#+begin_example
    input batch platform  N    time_avg     time_se
2     big     C  guarani 30 824.7546429 2.852807810
6     big     D  guarani 30 798.8587828 2.957736903
10    big     E  guarani 30 780.5554274 2.658481151
14    big     F  guarani 30 771.4025417 2.914139674
18 medium     A  guarani 30 100.3892080 0.484042387
21 medium     B  guarani 30  99.2527799 0.478672535
25 medium     C  guarani 30  95.0724998 0.584923080
29 medium     D  guarani 30  96.9286011 0.569612415
33 medium     E  guarani 30  92.5820661 0.512330528
37 medium     F  guarani 30  92.4204530 0.487320713
41  small     A  guarani 30   0.4956575 0.006162893
44  small     B  guarani 30   0.5281257 0.009840373
48  small     C  guarani 30   0.5544556 0.012537292
52  small     D  guarani 30   0.5818487 0.013258166
56  small     E  guarani 30   0.6681839 0.015388218
60  small     F  guarani 30   0.8698209 0.009727556
[1] 0.8672356
#+end_example

* 2016-05-17 Batch traces (figures)                     :noexport:Lucas:Tais:

Ok.

#+begin_src sh :results output :session :exports both
cd results/batch_time
#for each scenario
for scenario in `ls -1 | cut -d"_" -f1-3 | sort | uniq`; do
  #for each execution in temporal order
  CONTADOR=0
  for execution in `ls -1 ${scenario}* | sort --version-sort`; do
     NOME=`echo $execution | cut -d"_" -f1-3`_$CONTADOR.csv
     echo "$execution => $NOME"
     git mv $execution $NOME
     CONTADOR=$(($CONTADOR + 1))
  done
done
#+end_src

Let's commit this.

#+begin_src sh :results output :session :exports both
cd results/batch_time
#for each scenario/execution
head -n1 trace-1G.paje_611585_luiza_19.csv | \
   sed -e "s/(microseconds)//g" \
       -e "s/(Operations)//" \
       -e "s/(Bytes)//" \
       -e "s/Size/Operations/" \
       -e "s/$/, input, parsize, platform, execution/" \
       -e "s/Time//g" \
       -e "s/Number//" \
       -e "s/ //g" | \
       tr '[:upper:]' '[:lower:]' > batch_traces.csv
for i in `ls -1 trace-*.csv`; do
  #input
  INPUT=`echo $i | cut -d"." -f1 | sed -e "s/trace-//"`
  if [ $INPUT = "1G" ]; then
    INPUT="big"
  elif [ $INPUT = "128M" ]; then
    INPUT="medium"
  elif [ $INPUT = "128K" ]; then
    INPUT="small"
  else
    echo "Error #1"
    exit
  fi

  #size
  SIZE=`echo $i | cut -d"_" -f2`
  
  #platform
  PLATFORM=`echo $i | cut -d"_" -f3`

  #platform
  EXECUTION=`echo $i | cut -d"_" -f4 | sed "s/\.csv//"`

  #echo $i $INPUT $SIZE $PLATFORM $EXECUTION

  tail -n+2 $i | sed -e "s/$/,$INPUT,$SIZE,$PLATFORM,$EXECUTION/" \
                     -e "s/small,85,/small,F,/" \
                     -e "s/small,170,/small,E,/" \
                     -e "s/small,340,/small,D,/" \
                     -e "s/small,681,/small,C,/" \
                     -e "s/small,1363,/small,B,/" \
                     -e "s/small,2727,/small,A,/" \
                     -e "s/medium,78957,/medium,F,/" \
                     -e "s/medium,157914,/medium,E,/" \
                     -e "s/medium,315828,/medium,D,/" \
                     -e "s/medium,631657,/medium,C,/" \
                     -e "s/medium,1263314,/medium,B,/" \
                     -e "s/medium,2526628,/medium,A,/" \
                     -e "s/big,611585,/big,F,/" \
                     -e "s/big,1223170,/big,E,/" \
                     -e "s/big,2446340,/big,D,/" \
                     -e "s/big,4892680,/big,C,/" \
                     -e "s/big,9785361,/big,B,/"
done >> batch_traces.csv
#+end_src

#+RESULTS:

Great, finally.

Let's read the =batch_traces.csv= with R.

#+begin_src R :results output :session :exports both
df <- read.csv ("results/batch_time/batch_traces.csv");
df$start = df$start / 1000000;
df$end = df$end / 1000000;
head(df);
#+end_src

#+RESULTS:
#+begin_example
  batch    start      end duration operations  size input parsize      platform
1     1 0.260947 0.325175    64228       1363 47115 small       B guarani-orion
2     2 0.438277 0.494230    55953       1363 49281 small       B guarani-orion
3     3 0.514935 0.520468     5533          2   579 small       B guarani-orion
4     1 0.264858 0.331881    67023       1363 47115 small       B guarani-orion
5     2 0.455022 0.511381    56359       1363 49281 small       B guarani-orion
6     3 0.534869 0.536691     1822          2   579 small       B guarani-orion
  execution
1         0
2         0
3         0
4        10
5        10
6        10
#+end_example

#+begin_src R :results output graphics :file img/batch_time/batch_time_small_v1.pdf :exports both :width 9 :height 5 :session
library(ggplot2);
ggplot(df[df$input == "small" & df$execution <= 9,], aes(x=start, xend=end, y=execution, yend=execution, color=input)) +
  geom_segment(size=1.1) +
  theme_bw() + facet_grid (parsize~platform) +
  scale_colour_manual(values = c("green"), name="Input Size") +
  scale_y_continuous(breaks=c(0,3,6,9)) +
  ylab("Run (order)") +
  xlab("Time (s)") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_time/batch_time_small_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_time/batch_time_medium_v1.pdf :exports both :width 9 :height 5 :session
library(ggplot2);
ggplot(df[df$input == "medium" & df$execution <= 9,], aes(x=start, xend=end, y=execution, yend=execution, color=input)) +
  geom_segment(size=1.1) +
  theme_bw() + facet_grid (parsize~platform) +
  scale_colour_manual(values = c("blue"), name="Input Size") +
  scale_y_continuous(breaks=c(0,3,6,9)) +
  ylab("Run (order)") +
  xlab("Time (s)") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_time/batch_time_medium_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_time/batch_time_big_v1.pdf :exports both :width 9 :height 5 :session
library(ggplot2);
ggplot(df[df$input == "big" & df$execution <= 9,], aes(x=start, xend=end, y=execution, yend=execution, color=input)) +
  geom_segment(size=1.1) +
  theme_bw() + facet_grid (parsize~platform) +
  scale_colour_manual(values = c("red"), name="Input Size") +
  scale_y_continuous(breaks=c(0,3,6,9)) +
  ylab("Run (order)") +
  xlab("Time (s)") +
  ggtitle ("TBD") +
  theme_bw() +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_time/batch_time_big_v1.pdf]]



* 2016-05-17 Batch mem (figures)                        :noexport:Lucas:Tais:

Let's use =local= measurements.

#+begin_src R :results output :session :exports both
df <- read.csv ("results/batch_size/local.csv");
df <- df[complete.cases(df),];
df$sim_time <- as.numeric(as.character(df$sim_time));
df$insert_time <- as.numeric(as.character(df$insert_time));
df$sim_time = df$sim_time/1000000;
df$insert_time = df$insert_time/1000000;
df$max_mem = df$max_mem/1024/1024;
head(df);
#+end_src

#+RESULTS:
#+begin_example
  name run.no.in.std.order run.no run.no.std.rp  input batch   sim_time
2    1                   7      1           7.1  small     D   0.983336
3    2                  15      2          15.1    big     F 950.015134
4    3                   4      3           4.1  small     C   0.872588
5    4                  10      4          10.1  small     E   1.231774
6    5                  13      5          13.1  small     F   1.633785
7    6                  11      6          11.1 medium     E  93.070116
  insert_time    max_mem platform
2    0.202030   3.073425   orion1
3  401.292651 257.339241   orion1
4    0.227659   3.226997   orion1
5    0.256816   3.005371   orion1
6    0.285011   2.969864   orion1
7   52.138141  67.714127   orion1
#+end_example

Let's take the max of the max:

#+begin_src R :results output :session :exports both
library(dplyr);
k <- df %>%
     group_by(input, batch, platform) %>%
     summarize(N = n(),
               mem_max = max(max_mem)) %>%
     as.data.frame();
k
#+end_src

#+RESULTS:
#+begin_example
    input batch platform  N     mem_max
1     big     B   orion1 10 4085.928391
2     big     C  guarani 30 2041.474709
3     big     C    luiza 30 2041.564964
4     big     C   orion1 10 2041.475166
5     big     D  guarani 30 1020.575508
6     big     D    luiza 30 1020.667267
7     big     D   orion1 10 1020.575981
8     big     E  guarani 30  513.167862
9     big     E    luiza 30  513.259621
10    big     E   orion1 10  513.168320
11    big     F  guarani 30  257.338882
12    big     F    luiza 30  257.430183
13    big     F   orion1 10  257.339264
14 medium     A  guarani 30 1036.056984
15 medium     A    luiza 30 1036.147446
16 medium     B  guarani 30  527.779579
17 medium     B    luiza 30  528.854622
18 medium     B   orion1 10  527.780113
19 medium     C  guarani 30  264.647240
20 medium     C    luiza 30  264.737885
21 medium     C   orion1 10  264.647789
22 medium     D  guarani 30  133.295044
23 medium     D    luiza 30  133.386436
24 medium     D   orion1 10  133.295593
25 medium     E  guarani 30   67.714485
26 medium     E    luiza 30   67.806183
27 medium     E   orion1 10   67.714890
28 medium     F  guarani 30   35.100777
29 medium     F    luiza 30   35.979355
30 medium     F   orion1 10   35.101166
31  small     A  guarani 30    4.062813
32  small     A    luiza 30    4.160812
33  small     B  guarani 30    5.068680
34  small     B    luiza 30    3.606918
35  small     B   orion1 10    3.508286
36  small     C  guarani 30    3.227562
37  small     C    luiza 30    3.325630
38  small     C   orion1 10    3.227089
39  small     D  guarani 30    4.634178
40  small     D    luiza 30    3.172089
41  small     D   orion1 10    3.073601
42  small     E  guarani 30    4.566124
43  small     E    luiza 30    3.104179
44  small     E   orion1 10    3.005554
45  small     F  guarani 30    2.970490
46  small     F    luiza 30    3.068680
47  small     F   orion1 10    2.970024
#+end_example

#+begin_src R :results output graphics :file img/batch_size/local_mem_big_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k[k$input == "big",], aes(x=batch, y=mem_max, fill=input)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values = c("red","blue", "green"), name="Input Size") +
  ylab("Maximum Memory Utilization (Megabytes)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_mem_big_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_size/local_mem_medium_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k[k$input == "medium",], aes(x=batch, y=mem_max, fill=input)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values = c("blue"), name="Input Size") +
  ylab("Maximum Memory Utilization (Megabytes)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_mem_medium_v1.pdf]]


#+begin_src R :results output graphics :file img/batch_size/local_mem_small_v1.pdf :exports both :width 6 :height 4 :session
library(ggplot2);
ggplot(k[k$input == "small",], aes(x=batch, y=mem_max, fill=input)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values = c("green"), name="Input Size") +
  ylab("Maximum Memory Utilization (Megabytes)") +
  xlab("Batch Size") +
  ggtitle ("TBD") +
  theme_bw() + ylim(0,NA) + 
  facet_grid(~platform) +
  theme(legend.position="none"); # no legend since we have only small
#+end_src

#+RESULTS:
[[file:img/batch_size/local_mem_small_v1.pdf]]



* Conclusion
\label{chapter.conclusion}

+ proposal: extensible, more flexibility. deattach core.
+ other issues

   - implementation of plugins
   - pjdump - problem of outputting the states before container. space
     for improvements.
   - database:
       - results of batches. 
+ importance of implementation of plugins.
Creating plugins for the solution was extremely important to validate
the proposal. The first approach consisted in having instrumentation
points only for the events that generated complete entities, which was
soon discarded during the implementation of the
*PajeInsertDBPlugin*. We saw that, for example, to insert a state
entity, with foreign keys reffering a container and a type, the object
referenced must be already in the database. Thus, we noticed that, for
the extensibility to apply to the maximum number of potential
scenarios, it needed to give access to every type of event possible in
the Pajé format. Implementing this plugin took a lot of time, and
changes to it were made very frequently. It was interesting to observe
that the modificatons were only performed in the *PajeInsertDBPlugin*
class, demonstrating clearly that the handling of the results was
totally deattached from the core simulation.

For future work, it would be interesting to provide an interface for
the plugin package such as it could support multiple languages. 
of plugins, like .

+future work
 - improvement of entry points: variable for ex.
 - interface for plugins in other languages.
 - plugin to parallelize
 - options handler
 

not only the simulator
- plugins are important

*Future Work*
- Plugins in other languages

#+LATEX: \bibliography{References}


\appendix
* JavaCC Tutorial
\label{ap.javacc}

To build a grammar that will be compiled by =JavaCC= you only need to
create one file whith `.jj` extension. The structure of this file is
the following:

#+BEGIN_EXAMPLE
options{

}
#+END_EXAMPLE

A set of optional flags. An example, is the flag =STATIC=, which means
that there is only one parser for the JVM when set to true.

#+BEGIN_EXAMPLE
PARSER_BEGIN(MyGrammar)

public class MyGrammar {

}

PARSER_END(MyGrammar)
#+END_EXAMPLE

In this part, the Java code will be placed and it's the main class of
the program. Notice that the class must have the same name as the
generated parser.

#+BEGIN_EXAMPLE
TOKEN_MGR_DECLS:
{

}
#+END_EXAMPLE

The declarations used by the lexical analyser are placed in the
TOKEN_MGR_DECLS function.

Below these three structures, comes the lexical analysis where the
Token rules and parser actions can be written using a top-down
approach. First, the Tokens are declared, always using the word
"TOKEN" before. To exemplify the creation of a grammar in JavaCC, we
will create a language that consists in the declaration of integer and
char variables and assignments of values to these variables. All the
declarations come first, then the assignments. No verification will be
performed since it is just an example to clarify the JavaCC syntax. To
declare tokens, we use the following notation:

#+BEGIN_EXAMPLE
TOKEN: 
{
  < [NAME] : [EXPRESSION] >  
}
#+END_EXAMPLE

For our example of language we will have the following tokens: 

#+BEGIN_EXAMPLE
/* Integer Literals */
TOKEN : 
{
  < INTEGER: "0" | ["0"- "9"] (["0"-"9")* >
}

/*Variables, assignments and char values*/
TOKEN : 
{
  < VARIABLE: (["a"-"z", "A" - "Z"])+ >
  < ASSIGNMENT: "=" >
  < CHAR: (~["\""] | "\\" (["n","r","\\","\'","\""])) >
} 
/* Types */
TOKEN: 
{
  < INTEGER_TYPE : "int" >
  < CHAR_TYPE: "char" >
}
#+END_EXAMPLE

As we can see in the definitions above, it is not necessary to
explicit the word TOKEN for each one. It is usually separated to be
better organized and easier to understand. Although the token's
agroupation is not relevant, the order in which they are declared
is. When an input matches more than one token specification, the one
declared first will be considered.  There is also another kind of
regular expression production, which is the SKIP. Whatever matches the
regular expression defined in the SKIP scope will not be treated by
the parser.  Example:

#+BEGIN_EXAMPLE
SKIP: 
{
  "\n" 
  \| "\t"

} 
#+END_EXAMPLE

After the token declaration, comes the grammar rules. The rules are
declared as methods, that can have return values or not. The structure
of a method is the following:

#+BEGIN_EXAMPLE
[type] [name] ()
{}
{ 
  /* Rules */
}
#+END_EXAMPLE

The empty braces in the beginning of the method can be filled with
variable declarations in Java. More Java code can be added in the
middle of the rules by using braces. Inside the next braces, it is
possible to assign tokens, regular expressions or even methods to the
variables declared earlier. To refer to the tokens, we use its name
between angular brackets. Example:

#+BEGIN_EXAMPLE
void parser()
{ int number; }
{
  number = <INTEGER>
}
#+END_EXAMPLE

The first method defined will be the entrance to the parser and it can
contain methods inside that will be expanded later in the rules. The
entrance for the language we are using as an example would be as
follows:

#+BEGIN_EXAMPLE
void start()
{}
{
  declarations() assignments() <EOF>
}
#+END_EXAMPLE

EOF is a default token. It is important to guarantee that the file
will be parsed until the end. By the definition of our first method,
we assure that the declarations will obligatorily be in the beginning,
and the assignments at the end. Next, we expand the two methods to
address all the possibilities:

#+BEGIN_EXAMPLE
void declarations()
{}
{
  ((<INTEGER_TYPE> | <CHAR_TYPE>) <VARIABLE>)*
}

void assignments()
{}
{
  (<VARIABLE> <ASSIGNMENT> (<CHAR> | <INTEGER>))*
}

#+END_EXAMPLE

The multiplicity can be defined with the standard characters "*", "?",
"+", just as in the lexer. This example is just one possible approach
to define these rules. For example, you can use another non-terminal
to describe a value that will be assigned to a variable. In this case,
the assignments() rule would be expanded as follows:

#+BEGIN_EXAMPLE
void assignments()
{}
{
  (<VARIABLE> <ASSIGNMENT> assignable() )*
}

void assignable():
{}
{
  <CHAR> | <INTEGER> 
}
#+END_EXAMPLE

*** Usage with Java

In order to call the parser in a Java program, an object of the
MyGrammar class needs to be instantiated:

#+BEGIN_EXAMPLE
MyGrammar parser = new MyGrammar(input);
#+END_EXAMPLE

Then, once there is an instance of the parser, it is possible to call
the first method of the parser:

#+BEGIN_EXAMPLE
parser.start();
#+END_EXAMPLE

This code has a Java syntax and is placed in the main class presented
previously. Between the declarations of PARSER_BEGIN and PARSER_END,
any Java code can be placed to manipulate the results of the parsing.

#+BEGIN_EXAMPLE
PARSER_BEGIN(MyGrammar)
/* Imports */
public class MyGrammar {
    public static void main(String args []){
        /* Code to read the input */

        MyGrammar parser = new MyGrammar(input);
        parser.start();

       /* Java code to manipulate the parser results */
  
  }

}

PARSER_END(MyGrammar)
#+END_EXAMPLE
* Paje File Format Specification
\label{ap.pajeformat}

The Pajé Trace File Format has two parts: event definition and events.
The format of the event definition part has the following format:

- Every line of the event definition part of the Pajé format starts
  with the character "%".
- An event definition starts with "%EventDef" plus the =name= of the
  event followed by a =unique number= to identify it.
- An event definition ends with "%EndEventDef".
- Between the "%EventDef" and "%EndEventDef" lines there is a list of
  fields, one per line, with =name= and =type=.
- It is possible to have two events with the same name but different
  identification numbers. This is useful to specify different sets of
  fields for the same type of event.

The types of fields can be: 

=date=: a double precision floating-point number, which usually means
the seconds since the program started;

=int=: integer number;

=double=: floating-point number;

=hex=: address in hexadecimal;

=string=: string of characters;

 =color=: a sequence of three to four floating-point numbers between 0
and 1 inside double quotes. The values mean red, green, blue and
alpha(optional).

An example of event definition: 

#+BEGIN_EXAMPLE
%EventDef PajeNewEvent 17
%       Time date
%       Container string
%       Type string
%       Value double
%EndEventDef
#+END_EXAMPLE

** Events
\label{ap.events} 

After the event definition, the events themselves are described, one
in each line. Every event starts with the number that identifies it,
which was defined previously. For the example above, every line that
contains a *PajeNewEvent* event will start with the number 17. The
fields are separated by space or tab and must appear in the same order
as it was declared in the definition. In the example below, there is a
PajeNewEvent event with timestamp =3.14532=, of type =S=, in the
container =p1=, and with value =M=:

#+BEGIN_EXAMPLE
17 3.14532 p1 S M
#+END_EXAMPLE

Fields of type =string= don't need to be double quoted unless they are
empty or have a space or tab character. Before the entities can be
created, a hierarchy of types and containers must be defined and
containers need to be intantiated, since every entity belongs to a
container.

*** Types
Type doesn't have a timestamp and can be declared at anytime in a
trace file, as long as it is not used before its definition. It is
more common to have all the types defined in the beginning. There are
6 different type definitions, one for each sort of entity and one for
value objects:

*PajeDefineContainerType*: Must have the fields *Name* and *Type*, and
can have an optional field *Alias*. Defines a new container type
called *Name*, contained in a previously defined container of type
*Type*.

*PajeDefineStateType*: Must have the fields *Name* and *Type*, and can
have an optional field *Alias*. Defines a new state type called
*Name*, contained in a previously defined container of type *Type*.

*PajeDefineEventType*: Must have the fields *Name* and *Type*, and can
have an optional field *Alias*. Defines a new event type called
*Name*, contained in a previously defined container of type *Type*.

*PajeDefineVariableType*: Must have the fields *Name*, *Type* and
*Color*, and can have an optional field *Alias*. Defines a new
*variable type called *Name*, contained in a previously defined
*container of type *Type*, with the color *Color*. Notice that the
*color is associated to the type, and not to the object. Therefore,
*every variable of determined type will have the same color.

*PajeDefineLinkType*: Must have the fields *Name*, *Type*,
*StartContainerType* and *EndContainerType*, and can have an optional
*field *Alias*. Defines a new link type called *Name*, contained in a
*previously defined container of type *Type*, that connects the
*previously defined container type *StartContainerType* to the
*previously defined *EndContainerType*. Also, the container type given
*in *Type* must be an ancestral of both start and end container types.

*PajeDefineEntityValue*: Must have the fields *Name*, *Type* and
*Color*, and can have an optional field *Alias*. This is an optional
*event that defines the possible values of an entity type, which can
*be a State, Link or Event. Defines a new value called *Name* for the
*previously defined type *Type* with color *Color*. Notice that this
*value is an entity, differently from the one indentifying a variable,
*which is a double value.

*** Containers
Intances of containers can be created and destroyed during the trace
file. A container cannot be referenced after it was destroyed. The
events associated to the containers are timestamped.

*PajeCreateContainer*: Must have the fields *Time*, *Name*, *Type* and
*Container*, and can have an optional field *Alias*. Creates, at
*timestamp *Time*, a container instance called *Name*, of the
*container type *Type* and that is a child of the previously created
*container Container*.

*PajeDestroyContainer*: Must have the fields *Time*, *Name* and
*Type*. Destroys, at timestamp *Time*, a container instance called
*Name*, of the container type *Type*.

*** States
The state events change the values of a determined container's state,
by setting, pushing, popping and reseting.

*PajeSetState*: Must have the fields *Time*, *Type*, *Container* and
*Value*. Changes, at timestamp *Time*, to the value *Value*, the state
*type *Type*, of the container identified by *Container*.

*PajePushState*: Must have the fields *Time*, *Type*, *Container* and
*Value*. Pushes, at timestamp *Time*, the value *Value* of the state
*type *Type*, in the container identified by *Container*. The push
*event saves the existing value of the same state.

*PajePopState*: Must have the fields *Time*, *Type* and
*Container*. Pops, at timestamp *Time*, the last state of type *Type*
*in the container identified by *Container*.

*PajeResetState*: Must have the fields *Time*, *Type* and
*Container*. Clears, at timestamp *Time*, the state of type *Type* in
*the container identified by *Container*. If the stack is empty, the
*event does nothing.

*** Events
An event is something that is relevant enough to be acknowledged and
has a unique timestamp.

*PajeNewEvent*: Must have the fields *Time*, *Type*, *Container* and
*Value*. Instantiates, at timestamp *Time*, a remarkable event of type
*Type*, in the container *Container*, with value *Value*.

*** Variables
Variables are set at a specific timestamp and can have its value
changed throughout the simulation. The value of a variable is a double
precision floating-point number, which is different from the values of
the other entities. A variable must be set before changes to its value
can be made.

*PajeSetVariable*: Must have the fields *Time*, *Type*, *Container*
and *Value*. Instantiates, at timestamp *Time*, a variable of type
*Type*, in the container *Container*, with value *Value*.

*PajeAddVariable*: Must have the fields *Time*, *Type*, *Container*
and *Value*. Adds, at timestamp *Time*, a value *Value*, to an
existing variable of type *Type*, in the container *Container*.

*PajeAddVariable*: Must have the fields *Time*, *Type*, *Container*
and *Value*. Subtracts, at timestamp *Time*, a value *Value*, of an
existing variable of type *Type*, in the container *Container*.

*** Links
A link can start at a container and end in another one. Every
completed link is identified by a unique key.

*PajeStartLink*: Must have the fields *Time*, *Type*, *Container*,
*StartContainer*, *Value* and *Key*. Indicates, at timestamp *Time*,
*the beginning of a link of type _Type_, in container *Container*,
*starting from *StartContainer*, with value *Value*, and identified by
*key *Key*.

*PajeEndLink*: Must have the fields *Time*, *Type*, *Container*,
*EndContainer*, *Value* and *Key*. Indicates, at timestamp *Time*, the
*end of a link of type *Type*, in container *Container*, ending in
*EndContainer*, with value *Value*, and identified by key *Key*.

* PajeNG structures
\label{ap.pajeng}

The main structures used by the PajeNG simulator to manipulate the
entities are the following:

*Simulator*

=typeMap=: a map containing all the types that have been defined in
the simulation, with name or alias as key;

=contMap=: a map of the created containers also identified by the name
or alias.

*Container*

=stackStates=: a map identified by the type and with a vector of state
entities as the value. Every event of type *PajePushState* will add a
state entity to the end of the stack, while every *PajePopState* will
"remove" the last state in the vector by setting its end time;

=pendingLinks=: a map of pending links stores the communications that
were opened but have not been closed yet. The link key is the
identification, and the simulation fails if a container is destroyed,
or the simulation ends, before all the links are completed;

=linksUsedKeys=: a map listing all the keys for links that were
already used in this container.

=entities=: This map lists all the entities that belong to the
container, even if they were already listed in the other
structures. What identifies an entity is its type and container,
hence, the PajeType is the key of this map and a vector of entities is
the value. Here, we notice the importance of having the single parent
type class PajeType, and a unique parent entity class, PajeEntity, to
group together different types of objects. Since the objects are
pointers, the changes made in one structure are reflected in the other
ones. All of the variable and event objects are stored in this general
list of entities.

* Processing Command Line Arguments 
\label{ap.optionshandler}

Since handling command line arguments is not very straightforward in
Java, an external library \cite{optionhandler} was used. The command
line arguments are used for the user to pass information to the
simulator, such as the name of the file to be processed, or a comment
about the trace.

All of the arguments processing is done in one class:
*OptionsHandler*. The options that are needed in the simulation core
are stored in this single class. These are: 

*filename*: a string that receives the name of the trace file to be
read;

*comment*: a string that stores an optional comment about the file;

The centralization of the options has the objective of facilitating
the extensibility of the program. The arguments regarding a specific
plugin are sent directly to its proper object.

The constructor of this class receives the list of arguments that was
passed in the execution of the program and creates an object =opt= of
type =Options= with the arguments as parameter. 

#+BEGIN_EXAMPLE
import ml.options.Options;

public class OptionsHandler {

  public Options opt;

  public OptionsHandler(String args[]) {
	  opt = new Options(args);	
  }
}

Options opt
#+END_EXAMPLE

The Options type is the core of the library used, and all of the
argument's processing will be done in the =opt= instance. It is also
in the constructor that we set all of the possible options that can be
used by the user. To define a new one, we use the following line of
code:

#+BEGIN_EXAMPLE
opt.getSet().addOption("<alias>", Options.Separator.<SEPARATOR>, Options.Multiplicity.<MULTIPLICITY>);
#+END_EXAMPLE

=<alias>=: the alias that will be used to identify the option;

=<SEPARATOR>=: used for options that have a value. Can be *COLON*,
*EQUALS*, *BLANK* or *NONE*;

=<MULTIPLICITY>=: the multiplicity defines if the value is required or
optional, or if it can appear more than once. The possible values are:
*ONCE*, *ONCE_OR_MORE*, *ZERO_OR_ONE*, *ZERO_OR_MORE*.


The default for the prefix is a dash and is the one chosen for the
program. The constructor of Aiyra's OptionsHandler class has the
following definitions:

#+BEGIN_EXAMPLE
opt.getSet().addOption("f", Options.Separator.BLANK, Options.Multiplicity.ONCE);
opt.getSet().addOption("m", Options.Separator.BLANK, Options.Multiplicity.ZERO_OR_ONE);
opt.getSet().addOption("p", Options.Separator.BLANK, Options.Multiplicity.ZERO_OR_ONE);		
#+END_EXAMPLE

=-f=: required field that indicates the file to be parsed;

=-m=: an optional comment about the trace;

=-p=: the plugin to be used by the simulator.

To check if the user has passed the arguments properly, the Options
class provides a simple method thet returns a boolean:

#+BEGIN_EXAMPLE
opt.check
#+END_EXAMPLE

In the OptionsHandler class, this verification is done in the
=checkOptionsHelper= method, which prints a helper text to the user in
case the check fails.

#+BEGIN_EXAMPLE
public void checkOptionsHelper() {
	// true=ignoreUnmatched false=requireLast
	if (!this.opt.check(true, false)) {
		System.out.println("Your input is incorrect");
		System.out.println("Please use the following notation:");
		System.out.println("-f <path-to-filename>");
		System.out.println("-m <comment> (optional)");
		System.out.println("-p <plugin> (optional, default: null) ");
			
		System.exit(1);
	}
}
#+END_EXAMPLE

This validation must be done before the program continues, thus, this
method is already called in the constructor:

#+BEGIN_EXAMPLE
 public OptionsHandler(String args[]) {
	  opt = new Options(args);

      opt.getSet().addOption("f", Options.Separator.BLANK, Options.Multiplicity.ONCE);
      opt.getSet().addOption("m", Options.Separator.BLANK, Options.Multiplicity.ZERO_OR_ONE);
      opt.getSet().addOption("p", Options.Separator.BLANK, Options.Multiplicity.ZERO_OR_ONE);

      checkOptionsHelper();	
  }
#+END_EXAMPLE 

* Paje File Format Parser for JavaCC
\label{ap.grammar}
#+BEGIN_EXAMPLE
options
{
  static = false;
}

PARSER_BEGIN(PajeGrammar)
package br.ufrgs.inf.tlbellini;
import br.ufrgs.inf.tlbellini.lib.*;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.util.Scanner;
import java.util.ArrayList;
import ml.options.*;
import br.ufrgs.inf.tlbellini.plugins.*;

public class PajeGrammar
{

  public static ArrayList<PajeEventDefinition> eventDefinitions = new ArrayList<PajeEventDefinition>(); 
  public static PajeSimulator simulator = new PajeSimulator();
  public static OptionsHandler options;
 
  public static void main(String args []) throws ParseException, FileNotFoundException
  {
	FileInputStream input;
	Scanner sc = new Scanner(System.in);
	options = new OptionsHandler(args);
	input = null;
    if(args.length > 0)
    {
	input = new FileInputStream(options.opt.getSet().getOption("f").getResultValue(0));
	options.checkEntry();
    }else
    {
      options.checkOptionsHelper();
    }

    simulator.init();
    PajeGrammar parser = new PajeGrammar(input);
          
      try
      {
        switch (parser.paje())
        {
          case 4 :
          simulator.finish();
          System.out.println("OK!");
          case 1 : 
          System.out.println("Goodbye.");
          break;
          default: 
          break;
        }
      }
      catch (Exception e)
      {
        System.out.println("NOK.");
        System.out.println(e.getMessage());
      }
      catch (Error e)
      {
        System.out.println("Oops.");
        System.out.println(e.getMessage());
      }
    }
}

PARSER_END(PajeGrammar)

SKIP :
{
  " "
| "\r"
| "\t"
|  <  "#" (~["\r", "\n"])* ("\n" | "\r\n") >
}

TOKEN:
{
< BREAK: "\n" | "\r\n" >
}

TOKEN : /* EVENT DEFINITION */
{
  < EVENT_DEF_BEGIN : "%EventDef" >
| < EVENT_DEF : "%" >
| < EVENT_DEF_END : "%EndEventDef" >
| < EVENT_DEF_ALIAS : "Alias" >
| < EVENT_DEF_TYPE : "Type" | "ContainerType" | "EntityType" >
| < EVENT_DEF_NAME : "Name" >
| < EVENT_DEF_COLOR: "Color" >
| < EVENT_DEF_START_CONTAINER_TYPE : "StartContainerType" | "SourceContainerType">
| < EVENT_DEF_END_CONTAINER_TYPE : "EndContainerType" | "DestContainerType">
| < EVENT_DEF_CONTAINER : "Container">
| < EVENT_DEF_TIME : "Time">
| < EVENT_DEF_START_CONTAINER : "StartContainer" | "SourceContainer">
| < EVENT_DEF_END_CONTAINER : "EndContainer" | "DestContainer">
| < EVENT_DEF_VALUE : "Value">
| < EVENT_DEF_KEY : "Key">
| < EVENT_DEF_LINE : "Line">
| < EVENT_DEF_FILE : "File">
}

TOKEN :
{
  < EVENT_DEF_FIELD_TYPE_STRING : "string" >
| < EVENT_DEF_FIELD_TYPE_FLOAT : "float" >
| < EVENT_DEF_FIELD_TYPE_DOUBLE : "double" >
| < EVENT_DEF_FIELD_TYPE_INT : "int" >
| < EVENT_DEF_FIELD_TYPE_HEX : "hex" >
| < EVENT_DEF_FIELD_TYPE_DATE : "date" >
| < EVENT_DEF_FIELD_TYPE_COLOR : "color" >
}

TOKEN :
{
   < PAJE_DEFINE_CONTAINER_TYPE : "PajeDefineContainerType" >
 | < PAJE_DEFINE_VARIABLE_TYPE : "PajeDefineVariableType" >
 | < PAJE_DEFINE_STATE_TYPE : "PajeDefineStateType" >
 | < PAJE_DEFINE_EVENT_TYPE : "PajeDefineEventType" >
 | < PAJE_DEFINE_LINK_TYPE : "PajeDefineLinkType" >
 | < PAJE_DEFINE_ENTITY_VALUE : "PajeDefineEntityValue" >
}

TOKEN :
{
   < PAJE_CREATE_CONTAINER : "PajeCreateContainer" >
 | < PAJE_DESTROY_CONTAINER : "PajeDestroyContainer" >
}

TOKEN :
{
   < PAJE_SET_VARIABLE : "PajeSetVariable" >
 | < PAJE_ADD_VARIABLE : "PajeAddVariable" >
 | < PAJE_SUB_VARIABLE : "PajeSubVariable" >
}

TOKEN :
{
   < PAJE_SET_STATE : "PajeSetState" >
 | < PAJE_PUSH_STATE : "PajePushState" >
 | < PAJE_POP_STATE : "PajePopState" >
 | < PAJE_RESET_STATE : "PajeResetState" >
}

TOKEN :
{
   < PAJE_START_LINK : "PajeStartLink" >
 | < PAJE_END_LINK : "PajeEndLink" >
 | < PAJE_NEW_EVENT : "PajeNewEvent" >
}


TOKEN :
{
  < INT : (< DIGIT >)+ >
| < FLOAT : (< DIGIT >)+"."(< DIGIT >)+ >
| < #DIGIT : [ "0"-"9" ] >
| <STRING: "\"" (<LETTER> | < DIGIT > |  " ")* "\"" | (<LETTER> | <DIGIT>)+>
| <CHAR : (~["\""] | "\\" (["n","r","\\","\'","\""])) >
| < #LETTER : ["a"-"z", "A"-"Z", "-", "_", "."]  >
}

int paje() throws Exception:
{}
{
  declarations() events() < EOF >
  {
    return 4;
  }
  
}

void declarations() :
{PajeEventDefinition newDef;}
{
  (
    newDef = declaration()
  	{eventDefinitions.add(newDef);}
  )*

}

void empty():
{}
{
  < EOF >
}

PajeEventDefinition declaration():
{
  PajeEventId nameId;
  int id;
  ArrayList<PajeField> fieldsList;
}
{
	< EVENT_DEF_BEGIN > nameId = event_name() id = event_id() < BREAK >
	{ PajeEventDefinition def = new PajeEventDefinition(nameId, id); }
	fieldsList = fields() < EVENT_DEF_END > < BREAK >
	{
	 	def.addFields(fieldsList);
	 	return def;
	 }
}

PajeEventId event_name():
{}
{
  	< PAJE_DEFINE_CONTAINER_TYPE > { return PajeEventId.PajeDefineContainerType;} |
	< PAJE_DEFINE_VARIABLE_TYPE > {return  PajeEventId.PajeDefineVariableType;} |
	< PAJE_DEFINE_STATE_TYPE > { return PajeEventId.PajeDefineStateType;} |
	< PAJE_DEFINE_EVENT_TYPE > { return PajeEventId.PajeDefineEventType;} |
	< PAJE_DEFINE_LINK_TYPE >{ return PajeEventId.PajeDefineLinkType;} |
	< PAJE_DEFINE_ENTITY_VALUE >{ return PajeEventId.PajeDefineEntityValue;} |
	< PAJE_CREATE_CONTAINER >{ return PajeEventId.PajeCreateContainer;} |
	< PAJE_DESTROY_CONTAINER >{ return PajeEventId.PajeDestroyContainer;} |
	< PAJE_SET_VARIABLE >{ return PajeEventId.PajeSetVariable;} |
	< PAJE_ADD_VARIABLE >{ return PajeEventId.PajeAddVariable;} |
	< PAJE_SUB_VARIABLE >{ return PajeEventId.PajeSubVariable;} |
	< PAJE_SET_STATE >{ return PajeEventId.PajeSetState;} |
	< PAJE_PUSH_STATE >{ return PajeEventId.PajePushState;} |
	< PAJE_POP_STATE >{ return PajeEventId.PajePopState;} |
	< PAJE_RESET_STATE >{ return PajeEventId.PajeResetState;} |
	< PAJE_START_LINK >{ return PajeEventId.PajeStartLink;} |
	< PAJE_END_LINK >{ return PajeEventId.PajeEndLink;} |
	< PAJE_NEW_EVENT >{ return PajeEventId.PajeNewEvent;}
}
int event_id():
{Token value;}
{
  value = < INT > { return Integer.parseInt(value.image); }
}

 ArrayList<PajeField> fields():
{ ArrayList<PajeField> fieldsList = new ArrayList<PajeField>();
  PajeField newField; }
{
  (
    newField = field()
    {
     	fieldsList.add(newField);
   	}
  )*
  {return fieldsList;}
}

PajeField field():
{
  	PajeField newField = new PajeField();
 	PajeFieldName newFieldName;
	PajeFieldType newFieldType;
}

{ 
  < EVENT_DEF > newFieldName = field_name() newFieldType = field_type()
  {
    newField.setField(newFieldName);
  	newField.setType(newFieldType);
  }
  < BREAK >
  {return newField;}
}

PajeFieldName field_name() :
{}
{
  
< EVENT_DEF_ALIAS >{ return PajeFieldName.Alias; } |
	< EVENT_DEF_TYPE >{ return PajeFieldName.Type; } |
	< EVENT_DEF_NAME >{ return PajeFieldName.Name; } |
	< EVENT_DEF_COLOR >{ return PajeFieldName.Color; } |
	< EVENT_DEF_START_CONTAINER_TYPE >{ return PajeFieldName.StartContainerType; } |
	< EVENT_DEF_END_CONTAINER_TYPE >{ return PajeFieldName.EndContainerType; } |
	< EVENT_DEF_CONTAINER >{ return PajeFieldName.Container; } |
	< EVENT_DEF_TIME >{ return PajeFieldName.Time; } |
	< EVENT_DEF_START_CONTAINER >{ return PajeFieldName.StartContainer; } |
	< EVENT_DEF_END_CONTAINER >{ return PajeFieldName.EndContainer; } |
	< EVENT_DEF_VALUE >{ return PajeFieldName.Value; } |
	< EVENT_DEF_KEY >{ return PajeFieldName.Key; } |
    < EVENT_DEF_LINE >{ return PajeFieldName.Line; } |
    < EVENT_DEF_FILE >{ return PajeFieldName.File; } |
	< STRING >{ return PajeFieldName.Extra;}
}

PajeFieldType field_type():
{}
{
	< EVENT_DEF_FIELD_TYPE_STRING >{ return PajeFieldType.PAJE_string; } |
	< EVENT_DEF_FIELD_TYPE_FLOAT >{ return PajeFieldType.PAJE_float; } |
	< EVENT_DEF_FIELD_TYPE_DOUBLE >{ return PajeFieldType.PAJE_double; } |
	< EVENT_DEF_FIELD_TYPE_INT >{ return PajeFieldType.PAJE_int; } |
	< EVENT_DEF_FIELD_TYPE_HEX >{ return PajeFieldType.PAJE_hex; } |
	< EVENT_DEF_FIELD_TYPE_DATE >{ return PajeFieldType.PAJE_date; } |
	< EVENT_DEF_FIELD_TYPE_COLOR >{ return PajeFieldType.PAJE_color; }
}

void events() throws Exception:
{}
{
  (event())*
}

void event() throws Exception:
{}
{
	non_empty_event() | < BREAK >
}

void non_empty_event() throws Exception:
{
	PajeTraceEvent event = new PajeTraceEvent();
 	Token id; 
}
{
  id = < INT >
  {
  	ArrayList<String> fields;
  	event.setPajeEventDef(Integer.parseInt(id.image), eventDefinitions);
  	event.setLine(id.beginLine); 
  } 
  fields = arguments() <  BREAK >
  {
  	event.setFields(fields);
  	simulator.simulate(event);
  }
}

ArrayList<String> arguments():
{
	ArrayList<String> fields = new ArrayList<String>();
	String field;
}
{
  (
  	field = argument()
  	{
  		fields.add(field);
  	} 
  )*
  {return fields;}
}

String argument():
{	Token arg;
}
{
	arg = < STRING > {return arg.image.toString();}
	|arg = < FLOAT > {return arg.image.toString();}
	|arg = < INT > {return arg.image.toString();}

} 
#+END_EXAMPLE


* How to execute aiyra
\label{ap.aiyraexecute}

Clone the repository in [[https://github.com/taisbellini/aiyra]].

To compile aiyra navigate to the *workspace* folder and execute the
command =source compile.sh=.  It will give you information about the
usage.

To execute it perform the following command:
  
#+BEGIN_EXAMPLE
java br.ufrgs.inf.tlbellini.PajeGrammar -f <path to input Paje tracefile> -p <plugin> <option> <argument> ...
#+END_EXAMPLE

As arguments, you have the following options:
#+BEGIN_EXAMPLE
-f <path-to-filename>
-m <comment> (optional)
-p <plugin> (optional, default: null) 
The available plugins and its respective inputs are as follows: 
pjdump: PajeDump - dumps the data
-l <number-of-lines> (optional): number of lines per dump if pjdump chosen, default: 100000
mysql: MYSQL Database - sequential batches - insert data into a database using batches
-s <server-name> (optional): server name for the database. Default: localhost
-u <user-name> (optional): username to access database. Default: root
-pwd <password> (optional): password to access database. Default: root
-batch <max_size> (optional): Maximum size of batch to keep in memory
#+END_EXAMPLE

If you wish to use the *PajeInsertDBPlugin*, the database is described
by the script =pajeDB.sql= in Aiyra's main folder. Execute this plugin
in a connection in MySQL and provide the parameters for the host,
username and password.

* How to create a plugin

To create a plugin, extend the *PajePlugin* class and override the
abstract methods. The objects available for the plugin are described
in section \ref{section.plugin}.  If you wish to add arguments to your
plugin, refer to the Appendix \ref{ap.optionshandler}.
